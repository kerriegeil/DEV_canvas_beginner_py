{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1768413a-c9cc-4d37-85c9-cfe4eb0704d7",
   "metadata": {},
   "source": [
    "# Introduction to Pandas for Working with Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db644034-050c-4ae3-b249-80d0b26e714d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "## This notebook covers\n",
    "- Pandas data structures - dataframes and series\n",
    "- Selecting, slicing, and querying dataframes\n",
    "- Simple calculations with summary functions\n",
    "- Sorting and grouping data\n",
    "- Copying and renaming dataframe columns\n",
    "- Handling missing values\n",
    "- Merging dataframes and writing to file\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7f935-a8ca-4192-836f-ba569d498b98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "## Reminders\n",
    "\n",
    "Remember, you can use Jupyter's built-in table of contents (hamburger on the far left) to jump from heading to heading.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook should run in the Anaconda base environment. We'll discuss more about environments later, but for now look for something like the words \"Python3\" or \"base\" at the top right of this notebook. If it says \"No Kernel\", go to the Kernel tab, select Change Kernel, then select the Python3 or base kernel in the pop up window.\n",
    "\n",
    "---\n",
    "\n",
    "To run cells in this notebook place your cursor in the cell you want to run, then hit Shift+Enter.\n",
    "\n",
    "---\n",
    "\n",
    "To turn on line number for code cells go to View menu and click Show Line Numbers.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a10e75-ab62-4798-b547-2b80b1e896be",
   "metadata": {},
   "source": [
    "# I. Importing Necessary Packages\n",
    "The following code will load the packages you'll need for this notebook. Packages are collections of code that adds additional functionality to the core Python. It's best practice to import everything you need in one place at the top of your notebook or script.\n",
    "\n",
    "The \"as pd\" part of the pandas import statement below is giving the Pandas package an alias in our notebook. This way when we want to use functions from the Pandas package we can type, for example, ```pd.DataFrame()``` instead of the longer ```pandas.DataFrame()```. An alias can be anything really, but \"pd\" is the alias that the Pandas user community has settled on.\n",
    "\n",
    "This particular package was installed to your computer during the installation of Anaconda, so we can simply import it here instead of having to take the extra step of downloading it first. We'll cover how to download and import additional packages in a subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74e754-e313-4365-b6f0-ff58f88b352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b7ab8-1fba-45b1-ac14-585722000206",
   "metadata": {},
   "source": [
    "Packages that extend the core python language, such as the one we imported above usually have a website where you can find tons of helpful information. Package websites may include, for example, \"Getting Started\" tutorials, in-depth user guides, an API reference that documents the particulars of every single available function, and instructions on where to ask the user community questions, submit bug reports, or make software contributions. \n",
    "\n",
    "**If you need help, package websites are one of the first places you should look. Let's take a quick look at the Pandas website [https://pandas.pydata.org/](https://pandas.pydata.org/)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343d55f-4c6e-4ae3-a9dd-10264e3aa3fd",
   "metadata": {},
   "source": [
    "# II. Introduction to Pandas Data Structures\n",
    "\n",
    "On the Pandas website, the package developers describe the project's goal: pandas \"aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language.\"\n",
    "\n",
    "Pandas is a powerful tool for working with tabular data such as data stored in spreadsheets, databases, or other table-like formats. The main data structure Pandas used to hold data is called the *DataFrame*. A DataFrame is a 2-dimensional (rows and columns) structure that can store data of different types including strings, integers, floating point values, categorical data and more. DataFrames are like a spreadsheet - think of a table of data with headings and values. Each column of a Pandas DataFrame is its own data structure called a *Series*. Both data structures (DataFrame and Series) have an *index*. You can think of an index, for now, as a row or line number, but it can be anything, even text.\n",
    "\n",
    "Below are schematics of what a Pandas DataFrame and Series look like, where the darker grey boxes would hold headers (column names) and indexes (row names/numbers), while the lighter grey boxes would hold the data values.\n",
    "\n",
    "<table><tr>\n",
    "<!-- <td> <img src=\"https://pandas.pydata.org/docs/_images/01_table_dataframe.svg\" alt=\"schematic of a dataframe\" width=\"700\"/> </td>\n",
    "<td> <img src=\"https://pandas.pydata.org/docs/_images/01_table_series.svg\" alt=\"schematic of a series\" width=\"200\"/> </td> -->\n",
    "<td> <img src=\"images/01_table_dataframe.svg\" alt=\"schematic of a dataframe\" width=\"700\"/> </td>\n",
    "<td> <img src=\"images/01_table_series.svg\" alt=\"schematic of a series\" width=\"200\"/> </td>\n",
    "</tr></table\n",
    "         \n",
    "(Image Source: [Pandas Docs Getting Started Tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11aedc-3ab0-41a1-be18-0c096d1381f0",
   "metadata": {},
   "source": [
    "## Making a DataFrame from Scratch\n",
    "\n",
    "You can make a dataframe programmatically, as opposed to reading data from a file. For example, let's create one from lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bb90e-d62a-46f5-9bd0-986115883156",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfTuples = [(1,'089',32223,59730,98468,35297),\n",
    "                (2,'121',27183,56159,145165,52539),\n",
    "                (3,'073',27399,50075,57786,21237),\n",
    "                (4,'033',25065,59734,166234,56641),\n",
    "                (5,'059',23547,49620,140298,50185),\n",
    "                (6,'047',23111,44550,194029,69384),\n",
    "                (7,'149',22079,40404,48773,18941),\n",
    "                (8,'045',21935,44494,43929,17380),\n",
    "                (9,'081',21831,39049,82910,32086),\n",
    "                (10,'131',21691,43728,17786,6165)]\n",
    "\n",
    "listOfColumnNames = [\"rank\", \"county_fips\",\n",
    "                     \"per_capita_income\", \"median_household_income\",\n",
    "                     \"population\", \"num_households\"]\n",
    "\n",
    "countyData = pd.DataFrame(listOfTuples, columns = listOfColumnNames)\n",
    "        \n",
    "# if placed on a line by itself, you will get pretty output of the dataframe    \n",
    "countyData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b00b56-7d33-4543-a593-bdb366e8cf7b",
   "metadata": {},
   "source": [
    "Our data is now in a Pandas dataframe, which has 6 named columns of data (6 series) as well as a row index (the bold column without a header).\n",
    "\n",
    "Isolating a series from a dataframe would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2e0b8-6e2c-47ff-9a43-9cf69c5e9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "countyData[\"population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9040be0-8ec7-4f67-8bac-7a8341e2d328",
   "metadata": {},
   "source": [
    "You can see that the rendering of a series isn't pretty like that of a dataframe. But notice how a series isn't just the data values. The index remains attached and the column name is there as well. How do I know this is a Pandas series? We can use python's built-in function ```type()``` like we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfc778-a216-4ad7-9fd2-5fced4a8de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countyData[\"population\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ee1ea0-aab3-48fd-9c3a-17df4dfeb122",
   "metadata": {},
   "source": [
    "And for good measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521877c-c592-470d-b090-4001fa8e99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countyData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d59ce-331f-42ba-b83b-483a4f62e250",
   "metadata": {},
   "source": [
    "## Loading Tabular Data from a File into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb518a8-8120-4b9c-9494-fc19f92118aa",
   "metadata": {},
   "source": [
    "Pandas makes it very easy to load an excel file or other tabular data sources like .csv files into dataframes. \n",
    "\n",
    "The .csv file extension is a common file format for tabular data. CSV stands for comma separated values. Inside a CSV file, you will see rows of data with commas used between the values of each data column (i.e., \"comma delimited\"). Generally, we use .csv files instead of excel because excel has a limit on length (1,048,576 rows). (Also, reading an excel file with Pandas requires installation of an additional package. We'll cover that in the course module \"Input/Output of Different Data Formats\").\n",
    "\n",
    "A raw CSV file with a header row might look like this, for example:\n",
    "\n",
    "<pre>\n",
    "Book Title,Publisher,Price\n",
    "War and Peace,Vintage Classics,12.99\n",
    "\"Our Bodies, Ourselves\",Touchstone,48.38\n",
    "Putin's Playbook,\"Simon & Schuster, Inc.\",14.49\n",
    "</pre>\n",
    "\n",
    "Notice that the second book title listed and the third publisher name have a comma in the data value. Those values are surrounded by quotation marks to avoid Pandas interpreting the comma as a new column. This is important to do when you are creating your own csv data.\n",
    "\n",
    "Let's begin by loading an example data file that is .csv format into a Pandas dataframe. \n",
    "\n",
    "The example data used in this notebook is college football bowl data. While this particular data may not be relevant to your job or research, the data exploration and cleaning techniques we'll work through do broadly apply to any tabular data you may have (in .csv, .xls(x) or even .txt formats).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119550c2-e718-4bc0-80cd-34bd8b8acb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData = pd.read_csv('data/collegefootballbowl.csv')\n",
    "bowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add4af3-6946-42c3-93c5-bc8bb357afa0",
   "metadata": {},
   "source": [
    "Notice what gets printed to the screen when a dataframe has many rows. We can see the first 5 and last 5 rows of data, followed by the shape (rows, columns) of the full dataframe.\n",
    "\n",
    "Also notice some columns contain NaN values. NaN stands for \"not a number\" and usually represents a missing data value of type float. We'll cover more about different missing data values, how to handle them, and the missing data features Pandas offers later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84948a-9c0b-4b32-84ee-664cb16ab3fe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "**Sidebar about data management for tabular data:** It's important to, at minimum, create a data dictionary that describes what is in your data file, even if your data file contains column names. Often there is more information (metadata) that is required by future users of the data than just the column names and data values. Metadata for the collegefootballbowl.csv can be found in the [collegefootballbowl.txt](data/collegefootballbowl.txt) file, which tells future data users the original source of the data, when the data file was created, and contains a data dictionary that describes each column of data. This type of information is super important especially when your data values have units. Even future you may forget if your data is in Celsius or Fahrenheit, or if your precipitation data had units of cm, mm, inches, or hundredths of inches! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a06751-18dd-4370-9848-e3ea2ec1d22a",
   "metadata": {},
   "source": [
    "## Viewing the Head and Tail of a DataFrame\n",
    "\n",
    "```.head()``` lets us view the first N rows of a dataframe \n",
    "\n",
    "```.tail()``` lets us view the last N rows\n",
    "\n",
    "Using either one of these methods on a dataframe without any additional parameters will show you 5 rows. Enter an integer as a parameter to either function to view a different number of rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d457c-5289-4a18-8e2f-1ff5cd2316de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 rows\n",
    "bowlData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8801da8-336b-4995-9b5d-4da8f3872518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view last 10 rows\n",
    "bowlData.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7c684-7154-4cae-85c3-2972b0aab588",
   "metadata": {},
   "source": [
    "## Getting DataFrame Information\n",
    "\n",
    "### Shape Property: How Many Rows / Columns?\n",
    "\n",
    "```.shape``` returns a tuple (rows, columns) and is the most concise way to see how many total rows and columns are in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c412c2-7124-439a-ae17-215e4caba355",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632f9a6-cd7e-47db-8092-8a04837e3168",
   "metadata": {},
   "source": [
    "### Dtypes Property: Understanding the Data Types of Each Column\n",
    "\n",
    "Often you will need to know the data type of each column, ```.dtypes``` will give you that information.\n",
    "\n",
    "Anything column that says \"object\" is probably storing strings. int64 and float64 are numerical data (numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a0899-5b65-4b8b-a87a-6de4d4d74365",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fae4e0-8ec5-441a-a13c-409c674f3d4b",
   "metadata": {},
   "source": [
    "How were the data types for each column determined? \n",
    "\n",
    "When we read the .csv file using ```pd.read_csv()``` Pandas inferred the data type of each column based on the column's data values. If all values in a column appear to be integers, Pandas will infer that the column is data type int. Sometimes, there can be mistakes in your data file though. You could have a data column, for example winner_rank, that should contain all integers or missing values but a data entry mistake in your file has added 1 or more values that are non-numeric in that column. A lot of real data is \"messy\" like this. In these cases where there are mixed data types in a single column, Pandas usually reads the whole column as strings and assigns a data type of \"object\". This is in fact the case with our data columns winner_rank and loser_rank, which we will investigate a bit more later.\n",
    "\n",
    "### Describe Method: Summary of Numerical Data (count, mean, std, min, quartiles, max)\n",
    "\n",
    "You can access simple statistical information for numerical data columns using the ```.describe()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282162a-7672-4b4c-a77f-e2ce2c26c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52591c2e-ac14-4e71-ade7-9832d2e4a3cc",
   "metadata": {},
   "source": [
    "Notice that ```.describe()``` returns statistical information only for numerical data columns. \n",
    "\n",
    "For which year was the earliest data record in our dataframe collected? We can see the answer is the \"min\" of the year column, 1901.\n",
    "\n",
    "To see all columns, numeric or not, you can add a parameter to ```.describe()``` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17f6af-eea5-45b4-b80d-d40783592cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4391c2-599c-48f8-96fa-077434ffe32a",
   "metadata": {},
   "source": [
    "You can now see 3 additional statistics that operate only on non-numeric data columns: unique, top, and freq. NaN appears wherever the data type is not appropriate for the statistic. \n",
    "\n",
    "Who is the most common sponsor and how many times were they a sponsor? \n",
    "\n",
    "Looking to the sponsor column, the \"top\" row indicates the most common data value is Outback Steakhouse and the \"freq\" row indicates that Outback Steakhouse was a sponsor 26 times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeacfea-d1bc-4874-b722-c83f18e7c305",
   "metadata": {},
   "source": [
    "### Info Method: Understanding all Fields, Null Values, Dtypes, Shape, Size, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7218d-3c06-4c39-9b05-836e15302f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867edf4-b290-4d50-bde2-0883d2e0b62b",
   "metadata": {},
   "source": [
    "# III. Selecting/Slicing Data with .loc[]\n",
    "\n",
    "The Pandas function ```.loc[]``` allows us to directly access rows by index and columns by name ```.loc[row_index,column_name]``` or to access all rows of data based on a conditional ```.loc[condition]```. Let's take a look, starting with selecting by row index and column name.\n",
    "\n",
    "## Single Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850fcaa-cd2b-4f97-8118-0e2fca0a5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a single cell - the attendance column where row index is 1\n",
    "bowlData.loc[1, 'attendance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d120b-76e4-4eec-ac36-3caafa4a3ad0",
   "metadata": {},
   "source": [
    "If you have an integer in the \"row\" part of ```.loc[]```, Pandas assumes this is the *index* of the row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c9de2-801b-42c2-8451-20081587830b",
   "metadata": {},
   "source": [
    "## Single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aff753-e1c4-4988-a31b-0890067f1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT whole row of data where row index is 1\n",
    "bowlData.loc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4f577-4552-4bfa-bcdd-fc2089ad7cf1",
   "metadata": {},
   "source": [
    "A colon by itself means \"everything\", here specifically it means all columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854480b-bf3f-4f0b-9991-82edd5944bc4",
   "metadata": {},
   "source": [
    "## Single Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028a711-8950-4184-b8cd-5d95a2822fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a single column of data, just the atttendance column\n",
    "bowlData.loc[:, 'attendance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a488738-ca8c-42b3-af78-a75af45408c2",
   "metadata": {},
   "source": [
    "Here the colon by itself means all rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af8e3a-43af-4708-aeeb-130e5bd14bd5",
   "metadata": {},
   "source": [
    "## Slice of Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988115e8-db87-4f7d-a357-13b30121e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a slice of rows where row index is 1 to 6\n",
    "bowlData.loc[1:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479692d-9151-4c91-8860-c4deffdeda7c",
   "metadata": {},
   "source": [
    "A colon between two integers means a slice (here, meaning get multiple rows).\n",
    "\n",
    "Notice that a slice of a Pandas dataframe is inclusive of the ending row index 6, such that a slice of rows 1:6 returns 6 rows. Just a quick note that this is not always the case with other Python packages. Array slicing with the Numpy or Xarray packages, for example, are exclusive of the ending index, but we'll cover that in a different notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37db1f2-0b75-4da1-ac1a-9c5a8b892e44",
   "metadata": {},
   "source": [
    "## All Rows, Slice of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef74292-941c-4783-ab03-e6dc25ab039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT all rows but only a slice of columns from year to winner_rank \n",
    "bowlData.loc[:, 'year':'winner_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef2796-b265-419a-9cbd-76e28a04c3fc",
   "metadata": {},
   "source": [
    "Notice that when your output exceeds twenty lines, Jupyter will format nicely and show a bit at the ending and a bit at the end. It will do the same thing if your output has too many columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ab211-d2f2-41da-b495-f909fceda29c",
   "metadata": {},
   "source": [
    "## Slice of Rows, Slice of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fd3f7-515e-466b-b2f5-a73a58c52005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a slice of rows (index 10 to 15) and a slice of columns ('year' to 'winner_rank')\n",
    "bowlData.loc[10:15, 'year':'winner_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731cc36b-afd7-4f57-a130-cf71385ae92e",
   "metadata": {},
   "source": [
    "## Slice of Rows, Particular Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b49399-d2d7-47cd-a823-d58dc79601f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a slice of rows and two specific columns\n",
    "bowlData.loc[10:15, ['year', 'winner_rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c215366-4f44-4621-ad2e-ac2b6a9b5ecd",
   "metadata": {},
   "source": [
    "## All Rows Where Column has Certain Value\n",
    "\n",
    "Now, instead of putting row indexes and column names in ```.loc[]``` we'll use a condition instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f3c5f-d570-4cee-b66d-ce030a2102a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the year column is equal to 1901\n",
    "bowlData.loc[bowlData['year'] == 1901]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d359c6-f811-45cc-afd2-da6cf0125770",
   "metadata": {},
   "source": [
    "This returned only one row. If there were more rows where the year column was equal to 1901, then there would be more rows returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec8c89-fa1e-4368-8ea1-76c9d0974256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the sponsor column is missing data\n",
    "bowlData.loc[bowlData['sponsor'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22142e50-ff2f-4bf6-9a52-dae121b51ed2",
   "metadata": {},
   "source": [
    "## Rows Based on Column Comparison\n",
    "\n",
    "If we want to return all the games where the winner was ranked below (higher number) the loser (lower number), we could do it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43d9c4-d270-4bbf-bc27-3342accee392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the winner ranked below the loser\n",
    "bowlData.loc[bowlData['winner_rank'] > bowlData['loser_rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2c26e-96be-488e-b02f-c16a9b08e154",
   "metadata": {},
   "source": [
    "**Be careful in your analysis! Do you notice anything suspicious about the results that were returned?**\n",
    "\n",
    "We're looking for cases where the underdog won. For example, a team that was ranked 20th, beat the team that was ranked 10th (see index 1429). If you look closely in the results above you can see multiple examples of results returned that are NOT what we asked for. For example, index 1427 shows the winner had a better rank (8th) than the loser (13th). So, we've got incorrect results but did not receive an error message. \n",
    "\n",
    "**Why did this happen??** \n",
    "\n",
    "This comes back to the data type of the columns winner_rank and loser_rank. A ranking should be a numerical data type (such as int or float). If these columns had a numeric data type then we shouldn't have experienced any problems using the greater than operator. But if those columns contain non-numeric data (dtype object, which usually indicates string data) then that could yield unexpected results when comparing if one string is greater than another. Let's take a look at the data type for winner_rank and loser_rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36f71c-b1cc-4ba7-8296-cae8cc523d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData[['winner_rank', 'loser_rank']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48918ba0-2f67-4db8-b440-70bb55fbf329",
   "metadata": {},
   "source": [
    "Uh oh! We can see that Pandas determined the data type of those columns to be object, which is non-numeric. We discussed briefly already why this might happen. This should indicate to us that there must be some \"messy\" data somewhere in those columns, some data values that don't look like numbers. And due to this, Pandas is treating those data columns like strings instead of numbers. So, when we ask if the winner_rank is greater than the loser_rank, the process of comparing two string values with the greater than operator returns unexpected results.\n",
    "\n",
    "When beginning work with any dataset it is best to do some data cleaning first to make sure your columns are of the expected data types and remove any whacky data values in order to avoid problems like this one. Otherwise, you might easily miss the fact that your code isn't doing what you intended.\n",
    "\n",
    "Let's see what the problem is, clean up those two columns, ensure their dtype is numeric, and try our selection again.\n",
    "\n",
    "We'll start by using a pandas function that we haven't seen yet: ```.unique()``` on the winner_rank column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f967bc2-6828-4d16-bc17-c05b6803b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all the unique data values in the winner_rank column\n",
    "bowlData['winner_rank'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bc19c-8d32-40aa-9049-167d2fff5ec6",
   "metadata": {},
   "source": [
    "Look at that! Someone has entered a value of Pennsylvania in the column of winner_rank somewhere in the data file. That doesn't make sense at all. Notice, we also have some missing data (nan), but that shouldn't cause us problems here.\n",
    "\n",
    "Let's force the winner_rank data column to be numeric using another pandas function that we haven't seen yet: ```pd.to_numeric()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a5bad-b688-4124-a999-868c976f69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign all the values in the column winner_rank with numeric data values\n",
    "# any value that does not look like a number will be changed to the missing data value\n",
    "bowlData['winner_rank'] = pd.to_numeric(bowlData['winner_rank'], errors = 'coerce')\n",
    "\n",
    "# look again at the unique data values\n",
    "bowlData['winner_rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdc77d-34e2-4e02-9fbb-2dac67564078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the new data type\n",
    "bowlData['winner_rank'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f284048-5283-431b-9277-67a4eaea911a",
   "metadata": {},
   "source": [
    "How did we know what parameters to enter in ```pd.to_numeric()```? That information can be found in the Pandas documentation on the [API reference page for pd.to_numeric()](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html). Or you could have done a quick Google search for something like \"how to use pandas to_numeric\", which will bring up a great AI generated answer (at least it does in the USA at the time this notebook was created), the link to the Pandas API reference page, and many other websites that demonstrate how to use the function.\n",
    "\n",
    "Let's check out what the problem is with loser_rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6bacc-c77f-4ac1-9dbb-df1c66717a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all the unique data values\n",
    "bowlData['loser_rank'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da2223-ee0d-4014-b2e7-5c81a18802d0",
   "metadata": {},
   "source": [
    "Again, there's a 'TN' in the data values that doesn't make any sense. We'll do the same process to clean the loser_rank column and convert to a numeric data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf8aa1-d73b-4292-8da9-4774b8bd7433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign all the values in the column with numeric data values\n",
    "# any value that does not look like a number will be changed to the missing data value\n",
    "bowlData['loser_rank'] = pd.to_numeric(bowlData['loser_rank'], errors = 'coerce')\n",
    "\n",
    "# look again at the unique data values\n",
    "bowlData['loser_rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2449c-29e1-4788-bff7-97fad1c08fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the new data type\n",
    "bowlData['loser_rank'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb32b0-8e6b-45fa-a853-8b25ec0c75ad",
   "metadata": {},
   "source": [
    "Lastly, let's try the row selection by column comparison again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a1321-f0e6-414f-b8e7-9959833d360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all rows where the winner ranked below the loser\n",
    "bowlData.loc[bowlData['winner_rank'] > bowlData['loser_rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de099b-33fd-4859-8aea-c72680ea922d",
   "metadata": {},
   "source": [
    "Notice how the result now returns 215 rows whereas before we got 255 rows. Our original selection returned 40 incorrect results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa77ce-1fe2-4aa4-b3d8-f4b921da1305",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "## Exercise 1: Selecting with .loc[]\n",
    "\n",
    "Use ```.loc[]``` to select row indexes 100:110 and the three columns year, winner_points, loser_points from the bowlData dataframe.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa95ace-d96f-4ef5-88f7-010a6849131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef689798-e760-4a2f-929f-7fb506eed2b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "Now select the rows where attendance is greater than 100,000.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb3266-eb6f-4bef-be2a-4e1f7c02803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bac31a-e070-42e2-a85a-c7453862fdc7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "How many games in the dataframe had attendance greater than 100,000? Don't count the rows in your answer above, determine your answer programmatically.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb815d-6ea2-4cc9-b41e-4b59e7468c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3295a-d095-4207-a6e1-a4c5b7c8d1a0",
   "metadata": {},
   "source": [
    "# IV. Selecting data with .query()\n",
    "\n",
    "Similar to ```.loc[]```, the ```.query()``` method can be used to select rows in a dataframe based on a condition. Inside the ```.query()``` we can put a condition that looks a little bit like a database query. You may like this method if you have experience working with databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c4c6b-98d6-4834-b7b6-20c81d0bd19a",
   "metadata": {},
   "source": [
    "## Rows Where Column has Certain Numerical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af4575-2e34-40b9-a98d-6ed394c4a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where year is equal to 1901\n",
    "bowlData.query(\"year == 1901\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd8256-fb6c-48bd-96b9-9459b79fb3de",
   "metadata": {},
   "source": [
    "## Rows Where Column has String Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fc563-60b9-4476-80bb-6d03c94b3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the bowl_name is \"Rose Bowl\"\n",
    "# notice the single quotes around the string \"Rose Bowl\"\n",
    "bowlData.query(\"bowl_name == 'Rose Bowl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c979285-cbe7-4d64-b918-42545f2abc4e",
   "metadata": {},
   "source": [
    "## Rows Based on Substring Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf2a60-8037-4c44-ade3-84f2a3ca3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all rows where the word \"State\" appears in the winner_tie column\n",
    "bowlData.query(\"winner_tie.str.contains('State')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efcf6df-0570-4f1e-a21a-ce544a6bcd0e",
   "metadata": {},
   "source": [
    "## Rows Based on Column Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d2ddb-2292-4e57-a01a-414739a274b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the loser ranked higher (smaller number) than the winner (larger number)\n",
    "bowlData.query(\"loser_rank < winner_rank\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340d906f-6310-4bd8-8a88-d5c58cd609ab",
   "metadata": {},
   "source": [
    "## Rows Based on Comparison with a Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757dbd8-1f41-4052-97e4-a9eda277d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get the mean winner_points x 2\n",
    "# .mean() is calculating the mean of the entire winner_points column\n",
    "twiceTheMean = bowlData.winner_points.mean() * 2\n",
    "\n",
    "# then, we can use that value to query for winners with more than twice the mean\n",
    "bowlData.query(\"winner_points > @twiceTheMean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8602a21-a87c-45b7-adc3-eec65294854a",
   "metadata": {},
   "source": [
    "## Multiple Criteria Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba255f5-9e21-4f4e-9d34-68820a538031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the rows where the winner is Alabama, \n",
    "# AND Alabama had more than 50 points, \n",
    "# AND they weren't ranked number 1.\n",
    "bowlData.query(\"(winner_tie == 'Alabama') and (winner_points > 50) and (winner_rank > 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ba623-726d-430d-9ea1-d08f82c0f6bd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "## Exercise 2: Selecting with .query()\n",
    "\n",
    "Use ```.query()``` to find rows where the winner_tie column contains \"State\", the bowl_name contains \"Rose\", and the attendance is greater than 75,000.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82eae8a-9d2e-479a-ba70-795a6bce6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf44e2bf-33b0-483b-a8b4-d474d8adb2c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "Show programmatically how many rows your query found.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f48ed-aae1-4968-9b6b-3a8079bcd75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d708ce95-f025-4673-8fb2-d7a4f201ec3e",
   "metadata": {},
   "source": [
    "# V. Querying a Dataframe without .query()\n",
    "\n",
    "Different syntax can be used to accomplish the same data queries we covered above without using ```.query()```. This syntax may be preferable if you don't have experience working with databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0f6c6-bbf3-497f-94dc-966632b80065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where year is equal to 1901 using .query\n",
    "\n",
    "# copy of code from the .query() section\n",
    "# bowlData.query(\"year == 1901\") \n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[bowlData.year == 1901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d57ef67-8e0d-4f14-8d92-0e711633438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the bowl_name is \"Rose Bowl\"\n",
    "\n",
    "# copy of code from the .query section\n",
    "# bowlData.query(\"bowl_name == 'Rose Bowl'\") \n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[bowlData.bowl_name == \"Rose Bowl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb937af4-5de8-4e11-89e3-e03b11b2de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all rows where the word \"State\" appears in the winner_tie column\n",
    "\n",
    "# copy of code from the .query section\n",
    "# bowlData.query(\"winner_tie.str.contains('State')\")\n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[bowlData.winner_tie.str.contains('State')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c03f8-ccf9-469d-9964-6fbda5f22191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the loser ranked higher (smaller number) than the winner (larger number) using .query\n",
    "# copy of code from the .query section\n",
    "# bowlData.query(\"loser_rank < winner_rank\")\n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[bowlData.loser_rank < bowlData.winner_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cd6e8-b785-48aa-b1db-7ac8919f1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows Based on Comparison with a Variable\n",
    "\n",
    "# copy of code from the .query section\n",
    "# First, let's get the mean winner_points x 2\n",
    "# twiceTheMean = bowlData.winner_points.mean() * 2\n",
    "# then, we can use that value to query for winners with more than twice the mean\n",
    "# bowlData.query(\"winner_points > @twiceTheMean\")\n",
    "\n",
    "# alternative query syntax\n",
    "twiceTheMean = bowlData.winner_points.mean() * 2  # the same\n",
    "bowlData[bowlData.winner_points > twiceTheMean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f4a2b-e40a-4479-a0e3-eae6f38a6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the rows where the winner is Alabama, \n",
    "# AND Alabama had more than 50 points, \n",
    "# AND they weren't ranked number 1.\n",
    "\n",
    "# copy of code from the .query section\n",
    "# bowlData.query(\"(winner_tie == 'Alabama') and (winner_points > 50) and (winner_rank > 1)\")\n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[(bowlData.winner_tie == 'Alabama') & (bowlData.winner_points > 50) & (bowlData.winner_rank > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97e202-2970-4079-bb85-4da7688a281e",
   "metadata": {},
   "source": [
    "Notice the difference here where we're using ```&``` to link multiple conditions together instead of how in the previous notebook Python Language Basics we learned how to use the boolean operator ```and``` to link multiple conditions. The ```&``` is called  \"bitwise and\" whereas python ```and``` is called a \"logical and\". Unless using ```.query()```, Pandas requires bitwise and, bitwise or, and bitwise not, which are written as: ```&```, ```|```, ```~```. Otherwise, you will get an error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3d82e-9901-420b-9a32-1514d831773c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "## Exercise 3: Query without using .query()\n",
    "\n",
    "Without using ```.query()``` repeat the query from exercise 2 (find rows where the winner_tie column contains \"State\", the bowl_name contains \"Rose\", and the attendance is greater than 75,000).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f7795-ba8e-4138-a8e6-2bccce9b979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2334e5d-aabd-4983-af0f-27c1eab5bfcc",
   "metadata": {},
   "source": [
    "# VI. DataFrame Manipulation\n",
    "\n",
    "## Summary Functions\n",
    "\n",
    "Pandas offers a handful of summary functions that can be applied to a column or columns of a dataframe (series objects). These functions are:\n",
    "\n",
    "- ```.sum()``` Sum values of each object. \n",
    "- ```.count()``` Count non-NA values of each object. \n",
    "- ```.median()``` Median value of each object. \n",
    "- ```.quantile([0.25,0.75])``` Quantiles of each object. \n",
    "- ```.apply(function)``` Apply function to each object. \n",
    "- ```.min()``` Minimum value in each object. \n",
    "- ```.max()``` Maximum value in each object. \n",
    "- ```.mean()``` Mean value of each object. \n",
    "- ```.var()``` Variance of each object. \n",
    "- ```.std()``` Standard deviation of each object.\n",
    "\n",
    "We won't cover all of these, but let's try a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac01c4b4-f448-4ad7-89b2-232ff5cbeb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean of winner_points\n",
    "print(\"Winners had an average of \", bowlData['winner_points'].mean())\n",
    "\n",
    "# the median of loser_points\n",
    "print(\"Losers had a median of \", bowlData['winner_points'].median())\n",
    "\n",
    "# lowest score of a winning team\n",
    "print(f\"The highest score of a losing team is {bowlData['loser_points'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c599e41-166f-40e2-b493-64324491fff8",
   "metadata": {},
   "source": [
    "Wow, 61 points and still a loss... ooof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe08c1-9cc1-436e-9a97-68e59d5f7fad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "### Exercise 4: Find the standard deviation of a column\n",
    "\n",
    "Create a print statement similar those above to print the standard deviation of the winner_points column and loser_points column. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da598a68-a731-49e9-8bef-cb493f29df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6332d081-de63-4ea5-a9b9-1468253a0ef3",
   "metadata": {},
   "source": [
    "## Sorting Data\n",
    "\n",
    "Let's begin with a simple sort on a numeric data column with Pandas ```.sort_values()```. This function will sort numeric data in descending order by default unless you provide the parameter ```ascending=True```. \n",
    "\n",
    "First, we'll double check that the year column of the dataframe is numeric (we'll get into why we're doing this in a minute). Then we'll sort by year ascending and return only the year and winner_points columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e8575-6eb9-4318-becd-9897b120fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if year column is numeric\n",
    "bowlData.year.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a47dd-ad91-4feb-971a-ef0d0f6781f0",
   "metadata": {},
   "source": [
    "Excellent, we should be good to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f399cb-2983-4cb4-950a-920b48e82bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort specific columns by year\n",
    "bowlData[['year', 'winner_points']].sort_values(by = ['year'], ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26dfb52-76cd-4dca-a8a8-09aaf634f2fd",
   "metadata": {},
   "source": [
    "Now, let's do a more complex sort. Sort by winner_points descending to find the highest score by an upset winner (winner ranked lower than loser).\n",
    "\n",
    "We'll use the columns winner_rank and loser_rank to accomplish this sort (which we have already converted to numeric data) as well as the winner_points column.\n",
    "\n",
    "Let's double check the data type of the winner_points column before we sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb5a56-d00d-49c2-81e6-a290f8bc8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if winner_points column is numeric\n",
    "bowlData.winner_points.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99372a0a-6118-48c6-9ca0-de6fbfc565d0",
   "metadata": {},
   "source": [
    "Great, another numeric data column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da5fb79-0eae-4210-8d9d-472b818ce8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by winner_points to find the highest score by an upset winner\n",
    "bowlData[bowlData.winner_rank > bowlData.loser_rank].sort_values(by = ['winner_points'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b6885-130d-4c59-b9e5-ea55d29a8ba0",
   "metadata": {},
   "source": [
    "Notice that our code returned a lot of rows but we'll find the answer to our question in the first row in the winner_points column: 70.\n",
    "\n",
    "How would we do the same sort but return only the highest score by an upset winner as opposed to all the data rows that were returned in the code above?\n",
    "\n",
    "Since we are sorting with ```ascending = False```, the highest winner_points is located in the first row of returned data. In this case, the index of the first row is 727. We don't know ahead of time what the index value of the first row of results with be though. Don't worry! We can grab the first row of the sorted results using the integer row position 0 as opposed to using the row index by using ```.iloc[]```.\n",
    "\n",
    "From the results above we expect the output of the following code to be 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9541969-88da-4b40-a337-e5b18cf89eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by the winner_points to find the highest score by an upset winner\n",
    "bowlData[bowlData.winner_rank > bowlData.loser_rank].sort_values(by = ['winner_points'], ascending = False).iloc[0].loc['winner_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69713c85-1897-469f-86b4-00f62f48f0aa",
   "metadata": {},
   "source": [
    "Wow! What just happened? We used ```.iloc[0]``` to select only the first row of the results returned by sorting and ```.loc['winner_points']``` to return the value of the winner_points column from the results return by ```.iloc[0]```. \n",
    "\n",
    "Are you beginning to see the power of Pandas? We can string together many functions in a row to achieve what we're looking for.\n",
    "\n",
    "Does sorting work on strings? \n",
    "\n",
    "Yes, but you have to be careful! If your strings only contain letters, ```.sort_values()``` will sort from A to Z or Z to A as you'd expect. \n",
    "\n",
    "But, if your strings contain numbers or letters and numbers together, ```.sort_values()``` may not return the sort order that you're expecting. This is because Pandas sorts strings character by character using lexicographic order. This is also why we've been double checking that our columns with numbers are numeric and not object data type. \n",
    "\n",
    "Before we move on, let's work through a quick example of what happens if you sort strings that contain numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32639c1-e94e-4810-855c-a597b4ec1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with a column of data that looks like numbers, but are actually strings\n",
    "df = pd.DataFrame({'ranking': ['1', '3', '5', '2', '4', '10']})\n",
    "print(df.ranking.dtype)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d860c3-d39e-49a6-8c30-9711316f6770",
   "metadata": {},
   "source": [
    "The ranking column that looks like numeric data is actually strings. What happens when we sort ascending?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28a8f8-01f7-4a23-8f79-7e7a8d6f7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = ['ranking'], ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8afad1-22f2-4e18-a394-b0af299d5420",
   "metadata": {},
   "source": [
    "This is just something to be aware of. If you want to keep your numerical-looking data as strings but sort in numerical order, there would be some extra steps to execute. We won't cover that here but if you're interested you can find plenty of information on how to accomplish that on the web. For example, [this user question and answer on stackoverflow.com](https://stackoverflow.com/questions/37693600/how-to-sort-dataframe-based-on-particular-stringcolumns-using-python-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9b602-10e7-4ee4-bad4-b294c1350378",
   "metadata": {},
   "source": [
    "## Grouping Data\n",
    "\n",
    "```.groupby()``` will partition data into groups for you, which you can then operate on using functions like```.mean()```, ```.sum()```, etc. Let's start with a super simple example before we try to use ```.groupby()``` on our ```bowlData```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0d05b-a2be-487f-8eb6-4a767bb98cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new very simple dataframe \n",
    "# pretend we have been observing two falcons and two parrots\n",
    "# and we are keeping data records on their maximum observed flight speed in miles per hour\n",
    "birds = pd.DataFrame({'species' : ['falcon', 'falcon', 'parrot', 'parrot'],\n",
    "                   'individual' : ['f01', 'f02', 'squawky', 'pretty boy'],\n",
    "                   'age_class' : ['adult', 'adult', 'juvenile', 'adult'],\n",
    "                   'max_speed_mph' : [230., 240., 35., 40.]})\n",
    "birds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6c5fa-23a0-489a-a8da-17a2948d7497",
   "metadata": {},
   "source": [
    "We can use ```.groupby``` to find the average max speed of each species if we group the dataframe rows by the species column and then for each group of rows (there will be two groups: falcon rows and parrot rows) take the mean of the max_speed_mph column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb0a36-7b30-4ff4-86a2-27eef38e55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds.groupby(\"species\")[\"max_speed_mph\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59a289e-79f8-4cb9-8212-a78a75561cc5",
   "metadata": {},
   "source": [
    "Nice! The average max speed of all the falcons is 235 mph and the average max speed of all the parrots is 37.5 mph.\n",
    "\n",
    "Pandas ```.groupby()``` will work similarly on our much larger ```bowlData``` dataframe.\n",
    "\n",
    "Let's group by winner_tie (which is the name of the winning team) and then find the average numer of points the winning team scored (winner_points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ba502-1ea0-4652-aac4-64335a113e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgPointsByWinners = bowlData.groupby(\"winner_tie\")[\"winner_points\"].mean()\n",
    "avgPointsByWinners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd1fb3-afe7-420a-9ead-a811239f5ec8",
   "metadata": {},
   "source": [
    "With the ```bowlData```, it is a little more obvious to see the default behaviour of the ```.groupby()``` with regard to how the function sorts the result. ```.groupby()``` will sort ascending on the grouping column (here, winner_tie) when returning the result, which is why our result is sorted by winner_tie from A to Z. This is the default behavior unless you specify ```sort=False``` as a parameter in ```.groupby()```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95db8b-5e79-4d96-9eb1-21710e8f4e0a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "### Exercise 5: Using .groupby() \n",
    "\n",
    "Find the maximum observed flight speed for each species in the birds dataframe.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f3ef8-eb08-461b-a486-2f7612cc03bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c58c8-1c43-49fa-8911-ca3e90e51411",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "This next one is challenging and uses a function we haven't covered yet. See if you can work it out!\n",
    "\n",
    "For each species, find the name of the fastest individual. \n",
    "\n",
    "Hint: you will need to use ```.loc()```, ```.groupby()```, and also a function called ```.idxmax()``` (in that order). See if you can figure it out with some help from the web. The doc page for [.idxmax()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html) and [this user question and answer(s) from stackoverflow.com](https://stackoverflow.com/questions/39964558/pandas-max-value-index) may get you part of the way to the answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f74bb-0593-4ae3-b53b-18605ce23770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb63aa1-27b7-4988-8508-7f29edaadd1a",
   "metadata": {},
   "source": [
    "## Renaming Columns\n",
    "\n",
    "To change column names, the easiest way is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bad0f-b3c3-45c6-a32e-cdebed5e3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary where key is the old name and value is the new name\n",
    "columnMap = {\"mvp\" : \"most_valuable_player\", \"winner_tie\" : \"winner\"}\n",
    "\n",
    "bowlData = bowlData.rename(columns = columnMap, errors = \"raise\")\n",
    "\n",
    "bowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c2032-484e-4204-b6ec-5a65aae5ed2c",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Sometimes you will need to assess how much of your data is missing to make sure any statistics you apply to your data are robust. \n",
    "\n",
    "Sometimes having the missing data value (NaN) in your data is beneficial. Many functions will simply ignore missing data or propagate missing data values. For example, if you were to add one data value to another and the values were NaN + 5, the result would be NaN. This is often desirable.\n",
    "\n",
    "But in some cases, like for various machine learning techniques, you may need to ensure that there are no missing data values present in your data at all. In this case you may need to fill the missing data values with a different number or drop rows with missing data from your dataframe entirely.\n",
    "\n",
    "Let's look at the Pandas functions that can help us with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb03885-cdb3-4dba-b598-e0ecb2b33b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how many missing values are present in each column\n",
    "bowlData.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947c588-ac9b-4b2c-9240-6e29f2e49426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all the rows where winner_rank is missing\n",
    "bowlData[bowlData['winner_rank'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ebac7-3f77-4420-96e5-e0d0101008e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all missing values with 0 \n",
    "# notice we are making a copy of our data by saving the dataframe to a new variable here\n",
    "betterBowlData = bowlData.fillna(0)\n",
    "\n",
    "# let's see if any missing values are still present - shouldn't be\n",
    "betterBowlData.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42932d0d-38c9-4583-99f3-363bba074627",
   "metadata": {},
   "source": [
    "Let's pause for a minute to think about what we just did. We filled all NaN with 0. Does that make sense? Does it make sense to have winner_points = 0 or sponsor = 0? You can see how filling NaN with another value may end up being confusing to you later. So think carefully if you really need to replace missing data values, or if filling with another value like 0 will work for your analysis. \n",
    "\n",
    "Instead of filling NaN with a different value, you may need to drop full data rows if there are any missing values present. This is how you would do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd2988-4ef2-459e-8ffc-dbb9ab0cac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows where at least 1 column of data is NaN\n",
    "lessBowlData=bowlData.dropna(how = 'any')\n",
    "lessBowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745f455a-c01b-47ac-8cbc-d28812bbdffb",
   "metadata": {},
   "source": [
    "When we first loaded bowlData, we originally had 1527 rows of data and now after dropping all rows that have at least one missing value, we are left with only 269 rows of data.\n",
    "\n",
    "If the goal was to drop all rows where all columns contain the missing data value, you could use ```.dropna(how='all')```.\n",
    "\n",
    "## Creating New Columns Derived from Existing Columns\n",
    "\n",
    "Pandas allows us to easily use existing columns to calculate new data and save the calculations into a new column in the dataframe. \n",
    "\n",
    "Here's an example. Let's define a blowout as when the winning team beats the losing team by 21 or more points. The task now is to create a new column in our dataframe that indicates whether each game (row) in our dataset was a blowout. We'll fill the column with values of True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d6205-8424-42b2-8d6b-fea0f5103de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData['blowout'] = bowlData.winner_points - bowlData.loser_points >= 21\n",
    "bowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5876724-ad9f-42f2-a493-3e33439e4350",
   "metadata": {},
   "source": [
    "It's that simple! There is no looping required. Pandas is smart enough to do the subtraction row by row and fill the result in the appropriate place all on its own. Writing a loop would be much slower, which is the case for many Python packages. It's most efficient to use the built-in capabilities of whatever packages you're working with. Try to avoid looping wherever you can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68383e0-bb1a-435e-aa3c-87846aa62163",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "### Exercise 6: Copy an existing column to a new column\n",
    "\n",
    "Modify the dataframe bowlData by copying the year column to a new column called year_copy. Print bowlData to the screen to check your work.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b31dd-f79b-45a8-be92-f6fccb0e2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e323abf0-65e7-44ba-bfa7-d14c4d4f036d",
   "metadata": {},
   "source": [
    "## Merging DataFrames Together\n",
    "\n",
    "Let's pretend I have additonal college football bowl data hanging out in a separate csv file. The additional data has the same 'id' information (row index value) as in collegefootballbowl.csv, but not all id's (1-1527) are present. How do I join this additional data to the ```bowlData``` dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08e669-2a41-4f47-9055-f98ac72639c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "moreBowlData = pd.read_csv('data/morecollegefootballbowldata.csv')\n",
    "moreBowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730cdcf-3a40-4d8f-8d4c-fb22ba795bba",
   "metadata": {},
   "source": [
    "Oh wow, that's not much data! But let's merge it into ```bowlData``` anyway. The merge column will be the id column since that is the only common column between the two data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032d63e-1d08-4621-9335-6dfcb91287a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allBowlData = pd.merge(bowlData, moreBowlData, how = 'outer', on = 'id')\n",
    "allBowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2c00c-a4ee-40c9-9a98-82f9481e70b9",
   "metadata": {},
   "source": [
    "We can see that for the 3 id's where we have tickets_sold and best_selling_concession data, those data values now appear in the merged dataframe. And everywhere else in those two columns got filled with NaN. There are tons of ways to merge dataframes. Check out the [pd.merge() API reference](https://pandas.pydata.org/docs/reference/api/pandas.merge.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd53be-6504-4c0b-89a0-30a5c451720d",
   "metadata": {},
   "source": [
    "# VII. Writing a DataFrame to a File\n",
    "\n",
    "Pandas has a function ```.to_csv()``` for writing a dataframe to a .csv file.\n",
    "\n",
    "Let's write our bowl data to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87da19-5c4e-4250-8368-bfa26d56c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.to_csv(r'data/bowlData.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42da04-d7bc-454d-ba9b-818c51fb02af",
   "metadata": {},
   "source": [
    "Locate the file you just wrote, open it, and see what it looks like. If you open the file in JupyterLab it will look like a spreadsheet. If you open the file with any other text editor, you should see the comma separated header and data values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc2619-716d-47e8-b9a7-c6158797d07a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "# VIII. Exercise: Putting it All Together\n",
    "\n",
    "Use Pandas to read, clean, manipulate, and aggregate weather observations.\n",
    "\n",
    "## Read the data file\n",
    "Read the file at data/weatherdata.csv into a Pandas dataframe and render the dataframe to the screen\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0cf4c4-8402-49e6-8a4c-b33795d116b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded0cb9-e9ba-4484-ac96-43309f5ceb81",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "## Clean the data\n",
    "\n",
    "Look at all the columns of data. Do you see any mistakes?\n",
    "\n",
    "Replace 'LosAngeles' at index 3 with 'Los Angeles'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32612b2d-e39c-4317-b6bb-b47fcd404615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3467a56c-5a71-4302-b028-a63feff66b20",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "Show the data type of each column. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6cf83-d0c1-4ca6-87a5-eb2bb61263ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c246d-fe5f-4f41-a867-8fa14914f065",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "What data type is the windspeed_knots column? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950ddcb-3e7c-4784-b1c8-47aa174b2333",
   "metadata": {},
   "source": [
    "Type your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf2ecb-2a56-46ac-b6d3-7317567638bc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Why did Pandas assign that data type to windspeed_knots?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f087b-1658-4338-9432-b9671e5f3e9d",
   "metadata": {},
   "source": [
    "Type your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b532849-75da-4dfb-98bb-a4d1914d944c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Judging by the data values in the windspeed_knots column, what data type should windspeed_knots probably be?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfa38e-feda-45c3-8a3e-534b74eee0eb",
   "metadata": {},
   "source": [
    "Type your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbdc2f-4b03-4140-b8bb-47458a1348fb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Force the windspeed_knots column to be numeric, then show that the data type of the column did in fact change.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e0abe-8c28-435d-ba07-471ad287d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2af43-be8e-4d3c-835c-23235524ffdc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "## Create a new column of data\n",
    "\n",
    "Create a column of boolean data called ```IsRainy``` that indicates whether there was precipitation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d119e9b-2426-4adc-9bb8-f7a650caee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2dcbf4-fdc9-476e-9d5d-da1ef28825b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "## Calculate average temperature by city\n",
    "\n",
    "Calculate the average temperature for each city and save the result as new variable called ```avgT```.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19110cad-e27d-4e69-bf94-705aef3fd0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9765d01-9bcc-42f3-9c10-aafe3efc3e50",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "Looking at the ```df``` dataframe and the ```avgT``` results, how many data values were used to calculate the average New York temperature? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222a471-f968-495d-a543-445fd1c108bb",
   "metadata": {},
   "source": [
    "Type your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8de70-ca94-4f4e-a02c-d695bc24a655",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "## Sort the dataframe by date, ascending\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2170d7-c6a5-4a09-a46e-044fc0f4c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f4ae0-4d74-4445-8644-79e44eb13077",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "**Sidebar about sorting:** note that our dates are strings of numbers. We saw earlier what can happen when sorting strings that contain numbers! In this case the sort works because we have very few dates. If we had full months of date strings, this sort would be problematic due to the lexicographic sort order. If you have dates in your data, it's best to convert them to datetime objects, which is something we'll cover in a subsequent lesson.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e48227f-4314-4f86-a922-4b285eb50c61",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "## Write the dataframe to file\n",
    "\n",
    "Write the ```df``` data to a file called ```weatherdata_yourname.csv```, replacing yourname with your first name. Do not include the index column, but do include the column names.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e697e-4ae4-46bf-90c2-2ea2abb5fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc69db-015b-4e89-9d58-b099676a4ecf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "Does your csv file look like this inside?\n",
    "\n",
    "<img src=\"images/weatherdata.png\" alt=\"contents of cvs file\" width=\"400\"/>\n",
    "\n",
    "If so, congratulations! You've successfully completed this exercise.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a970b-12ed-4446-b07c-b180d1a0d14e",
   "metadata": {},
   "source": [
    "# IX. At a Glance: Language Covered\n",
    "\n",
    "The Pandas functionality that we covered at a glance...\n",
    "\n",
    "## Pandas functions\n",
    "\n",
    "```pd.DataFrame()```, ```pd.read_csv()```, ```pd.to_numeric()```, ```pd.merge()```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebaee89-4a3e-4888-aa88-cf90b2fa2221",
   "metadata": {},
   "source": [
    "## Pandas data structure (dataframe or series) methods \n",
    "\n",
    "```.head()```, ```.tail()```, ```.describe()```, ```.info()```, ```.unique()```, ```.query()```, ```.mean()```, ```.median()```, ```.max()```, ```.std()```, ```.sum()```, ```.sort_values()```, ```.groupby()```, ```.idxmax()```, ```.rename()```, ```.isna()```, ```.fillna()```, ```.dropna()```, ```.to_csv()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e7111-ad31-4b70-bf31-4f2e5b6f24c4",
   "metadata": {},
   "source": [
    "## Pandas data structure (dataframe or series) attributes\n",
    "\n",
    "```.shape```, ```.dtypes```, ```.loc```, ```.iloc```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27809429-0ce6-4744-9a9a-3892ca3f18c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "# X. Learning More About Pandas\n",
    "\n",
    "For more about Pandas, start on the Pandas website where you can find:\n",
    "\n",
    "- a nice cheat sheet https://pandas.pydata.org/docs/getting_started/index.html\n",
    "- a long list of community developed tutorials https://pandas.pydata.org/docs/getting_started/tutorials.html#communitytutorials\n",
    "- the user guide, which contains a bunch of 10 minute learning guides as well as more in-depth guides by topic https://pandas.pydata.org/docs/user_guide/index.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ba720-de69-4a98-bc96-76a2a35277ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
