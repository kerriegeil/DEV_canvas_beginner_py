{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1768413a-c9cc-4d37-85c9-cfe4eb0704d7",
   "metadata": {},
   "source": [
    "# Introduction to Pandas for Working with Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a10e75-ab62-4798-b547-2b80b1e896be",
   "metadata": {},
   "source": [
    "# I. Importing Necessary Packages\n",
    "The following code will include the packages you'll need for this notebook. Packages are collections of code that adds additional functionality to the core Python. It's best practice to import everything you need in one place at the top of your notebook or script.\n",
    "\n",
    "The \"as pd\" part of the pandas import statement below is giving the Pandas package an alias in our notebook. This way when we want to use functions from the Pandas package we can type, for example, ```pd.DataFrame()``` instead of the longer ```pandas.DataFrame()```. An alias can be anything really, but \"pd\" is the alias that the Pandas user community has settled on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb74e754-e313-4365-b6f0-ff58f88b352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b7ab8-1fba-45b1-ac14-585722000206",
   "metadata": {},
   "source": [
    "Packages that extend the core python language, such as the one we imported above usually have a website where you can find tons of helpful information. Package websites may include, for example, \"Getting Started\" tutorials, in-depth user guides, an API reference that documents the particulars of every single available function, and instructions on where to ask the user community questions, submit bug reports, or make software contributions. \n",
    "\n",
    "If you need help, package websites are one of the first places you should look. Let's take a quick look at the Pandas website **[https://pandas.pydata.org/](https://pandas.pydata.org/)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343d55f-4c6e-4ae3-a9dd-10264e3aa3fd",
   "metadata": {},
   "source": [
    "# II. Introduction to Pandas Data Structures\n",
    "\n",
    "On the Pandas website, the package developers describe the project's goal: pandas \"aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language.\"\n",
    "\n",
    "Pandas is a powerful tool for working with tabular data such as data stored in spreadsheets, databases, or other table-like formats. The main data structure Pandas used to hold data is called the *DataFrame*. A DataFrame is a 2-dimensional (rows and columns) structure that can store data of different types including strings, integers, floating point values, categorical data and more. DataFrames are like a spreadsheet - think of a table of data with headings and values. Each column of a Pandas DataFrame is its own data structure called a *Series*. Both data structures (DataFrame and Series) have an *index*. You can think of an index, for now, as a row or line number, but it can be anything, even text.\n",
    "\n",
    "Below are schematics of what a Pandas DataFrame and Series look like, where the darker grey boxes would hold headers (column names) and indexes (row names/numbers), while the lighter grey boxes would hold the data values.\n",
    "\n",
    "<table><tr>\n",
    "<!-- <td> <img src=\"https://pandas.pydata.org/docs/_images/01_table_dataframe.svg\" alt=\"schematic of a dataframe\" width=\"700\"/> </td>\n",
    "<td> <img src=\"https://pandas.pydata.org/docs/_images/01_table_series.svg\" alt=\"schematic of a series\" width=\"200\"/> </td> -->\n",
    "<td> <img src=\"images/01_table_dataframe.svg\" alt=\"schematic of a dataframe\" width=\"700\"/> </td>\n",
    "<td> <img src=\"images/01_table_series.svg\" alt=\"schematic of a series\" width=\"200\"/> </td>\n",
    "</tr></table\n",
    "         \n",
    "(Image Source: [Pandas Docs Getting Started Tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11aedc-3ab0-41a1-be18-0c096d1381f0",
   "metadata": {},
   "source": [
    "## Making a DataFrame from Scratch\n",
    "\n",
    "You can make a dataframe programmatically, as opposed to reading data from a file. For example, let's create one from lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345bb90e-d62a-46f5-9bd0-986115883156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>median_household_income</th>\n",
       "      <th>population</th>\n",
       "      <th>num_households</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>089</td>\n",
       "      <td>32223</td>\n",
       "      <td>59730</td>\n",
       "      <td>98468</td>\n",
       "      <td>35297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>27183</td>\n",
       "      <td>56159</td>\n",
       "      <td>145165</td>\n",
       "      <td>52539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>073</td>\n",
       "      <td>27399</td>\n",
       "      <td>50075</td>\n",
       "      <td>57786</td>\n",
       "      <td>21237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>033</td>\n",
       "      <td>25065</td>\n",
       "      <td>59734</td>\n",
       "      <td>166234</td>\n",
       "      <td>56641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>059</td>\n",
       "      <td>23547</td>\n",
       "      <td>49620</td>\n",
       "      <td>140298</td>\n",
       "      <td>50185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>047</td>\n",
       "      <td>23111</td>\n",
       "      <td>44550</td>\n",
       "      <td>194029</td>\n",
       "      <td>69384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>149</td>\n",
       "      <td>22079</td>\n",
       "      <td>40404</td>\n",
       "      <td>48773</td>\n",
       "      <td>18941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>045</td>\n",
       "      <td>21935</td>\n",
       "      <td>44494</td>\n",
       "      <td>43929</td>\n",
       "      <td>17380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>081</td>\n",
       "      <td>21831</td>\n",
       "      <td>39049</td>\n",
       "      <td>82910</td>\n",
       "      <td>32086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>131</td>\n",
       "      <td>21691</td>\n",
       "      <td>43728</td>\n",
       "      <td>17786</td>\n",
       "      <td>6165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank county_fips  per_capita_income  median_household_income  population  \\\n",
       "0     1         089              32223                    59730       98468   \n",
       "1     2         121              27183                    56159      145165   \n",
       "2     3         073              27399                    50075       57786   \n",
       "3     4         033              25065                    59734      166234   \n",
       "4     5         059              23547                    49620      140298   \n",
       "5     6         047              23111                    44550      194029   \n",
       "6     7         149              22079                    40404       48773   \n",
       "7     8         045              21935                    44494       43929   \n",
       "8     9         081              21831                    39049       82910   \n",
       "9    10         131              21691                    43728       17786   \n",
       "\n",
       "   num_households  \n",
       "0           35297  \n",
       "1           52539  \n",
       "2           21237  \n",
       "3           56641  \n",
       "4           50185  \n",
       "5           69384  \n",
       "6           18941  \n",
       "7           17380  \n",
       "8           32086  \n",
       "9            6165  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfTuples = [(1,'089',32223,59730,98468,35297),\n",
    "                (2,'121',27183,56159,145165,52539),\n",
    "                (3,'073',27399,50075,57786,21237),\n",
    "                (4,'033',25065,59734,166234,56641),\n",
    "                (5,'059',23547,49620,140298,50185),\n",
    "                (6,'047',23111,44550,194029,69384),\n",
    "                (7,'149',22079,40404,48773,18941),\n",
    "                (8,'045',21935,44494,43929,17380),\n",
    "                (9,'081',21831,39049,82910,32086),\n",
    "                (10,'131',21691,43728,17786,6165)]\n",
    "\n",
    "listOfColumnNames = [\"rank\",\"county_fips\",\"per_capita_income\"\n",
    "                     ,\"median_household_income\",\"population\"\n",
    "                     ,\"num_households\"]\n",
    "\n",
    "countyData = pd.DataFrame(listOfTuples,columns=listOfColumnNames)\n",
    "        \n",
    "# if placed on a line by itself, you will get pretty output of the dataframe    \n",
    "countyData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b00b56-7d33-4543-a593-bdb366e8cf7b",
   "metadata": {},
   "source": [
    "Our data is now in a Pandas dataframe, which has 6 named columns of data (6 series) as well as a row index (the bold column without a header).\n",
    "\n",
    "Isolating a series from a dataframe would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2e0b8-6e2c-47ff-9a43-9cf69c5e9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "countyData[\"population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9040be0-8ec7-4f67-8bac-7a8341e2d328",
   "metadata": {},
   "source": [
    "You can see that the rendering of a series isn't pretty like that of a dataframe. But notice how a series isn't just the data values. The index remains attached and the column name is there as well. How do I know this is a Pandas series? We can use python's built-in function ```type()``` like we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfc778-a216-4ad7-9fd2-5fced4a8de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countyData[\"population\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ee1ea0-aab3-48fd-9c3a-17df4dfeb122",
   "metadata": {},
   "source": [
    "And for good measure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521877c-c592-470d-b090-4001fa8e99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countyData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d59ce-331f-42ba-b83b-483a4f62e250",
   "metadata": {},
   "source": [
    "## Loading Tabular Data from a File into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb518a8-8120-4b9c-9494-fc19f92118aa",
   "metadata": {},
   "source": [
    "Pandas makes it very easy to load an excel file or other tabular data sources like .csv files into dataframes. \n",
    "\n",
    "The .csv file extension is a common file format for tabular data. CSV stands for comma separated values. Inside a CSV file, you will see rows of data with commas used between the values of each data column (i.e., \"comma delimited\"). Generally, we use .csv files instead of excel because excel has a limit on length (1,048,576 rows). \n",
    "\n",
    "For example, a raw CSV file with a header row might look like this:\n",
    "\n",
    "<pre>\n",
    "Book Title,Publisher,Price\n",
    "War and Peace,Vintage Classics,12.99\n",
    "\"Our Bodies, Ourselves\",Touchstone,48.38\n",
    "Putin's Playbook,\"Simon & Schuster, Inc.\",14.49\n",
    "</pre>\n",
    "\n",
    "Notice that the second book title listed and the third publisher name have a comma in the data value. Those values are surrounded by quotation marks to avoid Pandas interpreting the comma as a new column. This is important to do when you are creating your own csv data.\n",
    "\n",
    "Let's begin by loading an example data file that is .csv format into a Pandas dataframe. \n",
    "\n",
    "The example data used in this notebook is college football bowl data. While this particular data may not be relevant to your job or research, the data exploration and cleaning techniques we'll work through do broadly apply to any tabular data you may have (in .csv, .xls(x) or even .txt formats).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119550c2-e718-4bc0-80cd-34bd8b8acb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_points</th>\n",
       "      <th>loser_tie</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_points</th>\n",
       "      <th>attendance</th>\n",
       "      <th>mvp</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>bowl_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>12/29/2021</td>\n",
       "      <td>Wed</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>59121.0</td>\n",
       "      <td>Oklahoma RB Kennedy Brooks, Oklahoma S Pat Fields</td>\n",
       "      <td>Valero</td>\n",
       "      <td>Alamo Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>12/29/2020</td>\n",
       "      <td>Tue</td>\n",
       "      <td>Texas</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>10822.0</td>\n",
       "      <td>Texas RB Bijan Robinson, Texas LB DeMarvion Ov...</td>\n",
       "      <td>Valero</td>\n",
       "      <td>Alamo Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>Tue</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>Utah</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>60147.0</td>\n",
       "      <td>Texas QB Sam Ehlinger, Texas LB Joseph Ossai</td>\n",
       "      <td>Valero</td>\n",
       "      <td>Alamo Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>12/28/2018</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Washington State</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>Iowa State</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>60675.0</td>\n",
       "      <td>Washington State QB Gardner Minshew, Washingto...</td>\n",
       "      <td>Valero</td>\n",
       "      <td>Alamo Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>12/28/2017</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Texas Christian</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>57653.0</td>\n",
       "      <td>TCU QB Kenny Hill, TCU LB Travin Howard</td>\n",
       "      <td>Valero</td>\n",
       "      <td>Alamo Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>1523</td>\n",
       "      <td>2004</td>\n",
       "      <td>12/30/2004</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Northern Illinois</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>Troy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>21456.0</td>\n",
       "      <td>RB Dewhitt Betterson (Troy), DB Lionel Hickenb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silicon Valley Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1524</td>\n",
       "      <td>2003</td>\n",
       "      <td>12/30/2003</td>\n",
       "      <td>Tue</td>\n",
       "      <td>Fresno State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20126.0</td>\n",
       "      <td>RB Rodney Davis (Fresno State), DL Garrett McI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silicon Valley Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>1525</td>\n",
       "      <td>2002</td>\n",
       "      <td>12/31/2002</td>\n",
       "      <td>Tue</td>\n",
       "      <td>Fresno State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>10132.0</td>\n",
       "      <td>RB Rodney Davis (Fresno State), DL Jason Stewa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silicon Valley Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1526</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/31/2001</td>\n",
       "      <td>Mon</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>Fresno State</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>30456.0</td>\n",
       "      <td>WR Charles Rogers (Michigan State), DL Nick My...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silicon Valley Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>1527</td>\n",
       "      <td>2000</td>\n",
       "      <td>12/31/2000</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>Fresno State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>26542.0</td>\n",
       "      <td>QB Mike Thiessen (Air Force), LB Tim Skipper (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silicon Valley Bowl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year        date  day         winner_tie winner_rank  \\\n",
       "0        1  2021  12/29/2021  Wed           Oklahoma          14   \n",
       "1        2  2020  12/29/2020  Tue              Texas          20   \n",
       "2        3  2019  12/31/2019  Tue              Texas         NaN   \n",
       "3        4  2018  12/28/2018  Fri   Washington State          12   \n",
       "4        5  2017  12/28/2017  Thu    Texas Christian          13   \n",
       "...    ...   ...         ...  ...                ...         ...   \n",
       "1522  1523  2004  12/30/2004  Thu  Northern Illinois         NaN   \n",
       "1523  1524  2003  12/30/2003  Tue       Fresno State         NaN   \n",
       "1524  1525  2002  12/31/2002  Tue       Fresno State         NaN   \n",
       "1525  1526  2001  12/31/2001  Mon     Michigan State         NaN   \n",
       "1526  1527  2000  12/31/2000  Sun          Air Force         NaN   \n",
       "\n",
       "      winner_points     loser_tie loser_rank  loser_points  attendance  \\\n",
       "0                47        Oregon         15            32     59121.0   \n",
       "1                55      Colorado        NaN            23     10822.0   \n",
       "2                38          Utah         12            10     60147.0   \n",
       "3                28    Iowa State         25            26     60675.0   \n",
       "4                39      Stanford         15            37     57653.0   \n",
       "...             ...           ...        ...           ...         ...   \n",
       "1522             34          Troy        NaN            21     21456.0   \n",
       "1523             17          UCLA        NaN             9     20126.0   \n",
       "1524             30  Georgia Tech        NaN            21     10132.0   \n",
       "1525             44  Fresno State         20            35     30456.0   \n",
       "1526             37  Fresno State        NaN            34     26542.0   \n",
       "\n",
       "                                                    mvp sponsor  \\\n",
       "0     Oklahoma RB Kennedy Brooks, Oklahoma S Pat Fields  Valero   \n",
       "1     Texas RB Bijan Robinson, Texas LB DeMarvion Ov...  Valero   \n",
       "2          Texas QB Sam Ehlinger, Texas LB Joseph Ossai  Valero   \n",
       "3     Washington State QB Gardner Minshew, Washingto...  Valero   \n",
       "4               TCU QB Kenny Hill, TCU LB Travin Howard  Valero   \n",
       "...                                                 ...     ...   \n",
       "1522  RB Dewhitt Betterson (Troy), DB Lionel Hickenb...     NaN   \n",
       "1523  RB Rodney Davis (Fresno State), DL Garrett McI...     NaN   \n",
       "1524  RB Rodney Davis (Fresno State), DL Jason Stewa...     NaN   \n",
       "1525  WR Charles Rogers (Michigan State), DL Nick My...     NaN   \n",
       "1526  QB Mike Thiessen (Air Force), LB Tim Skipper (...     NaN   \n",
       "\n",
       "                bowl_name  \n",
       "0              Alamo Bowl  \n",
       "1              Alamo Bowl  \n",
       "2              Alamo Bowl  \n",
       "3              Alamo Bowl  \n",
       "4              Alamo Bowl  \n",
       "...                   ...  \n",
       "1522  Silicon Valley Bowl  \n",
       "1523  Silicon Valley Bowl  \n",
       "1524  Silicon Valley Bowl  \n",
       "1525  Silicon Valley Bowl  \n",
       "1526  Silicon Valley Bowl  \n",
       "\n",
       "[1527 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowlData = pd.read_csv('data/collegefootballbowl.csv')\n",
    "bowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add4af3-6946-42c3-93c5-bc8bb357afa0",
   "metadata": {},
   "source": [
    "Notice what gets printed to the screen when a dataframe has many rows. We can see the first 5 and last 5 rows of data, followed by the shape (rows, columns) of the full dataframe.\n",
    "\n",
    "Also notice some columns contain NaN values. NaN stands for \"not a number\" and usually represents a missing data value of type float. We'll cover more about different missing data values, how to handle them, and the missing data features Pandas offers later.\n",
    "\n",
    "Sidebar about data management for tabular data: It's important to at minimum create a data dictionary that describes what is in your data file, even if your data file contains column names. Often there is more information (metadata) that is required by future users of the data than just the column names and data values. Metadata for the collegefootballbowl.csv can be found in the [collegefootballbowl.txt](data/collegefootballbowl.txt) file, which tells future data users the original source of the data, when the data file was created, and contains a data dictionary that describes each column of data. This type of information is super important especially when your data values have units. Even future you may forget if your data is in Celsius or Fahrenheit, or if your precipitation data had units of cm, mm, inches, or hundredths of inches! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a06751-18dd-4370-9848-e3ea2ec1d22a",
   "metadata": {},
   "source": [
    "## Viewing the Head and Tail of a DataFrame\n",
    "\n",
    "```.head()``` lets us view the first N rows of a dataframe \n",
    "\n",
    "```.tail()``` lets us view the last N rows\n",
    "\n",
    "Using either one of these methods on a dataframe without any additional parameters will show you 5 rows. Enter an integer as a parameter to either function to view a different number of rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d457c-5289-4a18-8e2f-1ff5cd2316de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 rows\n",
    "bowlData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8801da8-336b-4995-9b5d-4da8f3872518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view last 10 rows\n",
    "bowlData.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7c684-7154-4cae-85c3-2972b0aab588",
   "metadata": {},
   "source": [
    "## Getting DataFrame Information\n",
    "\n",
    "### Shape Property: How Many Rows / Columns?\n",
    "\n",
    "```.shape``` returns a tuple (rows, columns) and is the most concise way to see how many total rows and columns are in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c412c2-7124-439a-ae17-215e4caba355",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632f9a6-cd7e-47db-8092-8a04837e3168",
   "metadata": {},
   "source": [
    "### Dtypes Property: Understanding the Data Types of Each Column\n",
    "\n",
    "Often you will need to know the data type of each column, ```.dtypes``` will give you that information.\n",
    "\n",
    "Anything column that says \"object\" is probably storing strings. int64 and float64 are numerical data (numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a0899-5b65-4b8b-a87a-6de4d4d74365",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fae4e0-8ec5-441a-a13c-409c674f3d4b",
   "metadata": {},
   "source": [
    "How were the data types for each column determined? \n",
    "\n",
    "When we read the .csv file using ```pd.read_csv()``` Pandas inferred the data type of each column based on the column's data values. If all values in a column appear to be integers, Pandas will infer that the column is data type int. Sometimes, there can be mistakes in your data file though. You could have a data column, for example winner_rank, that should contain all integers or missing values but a data entry mistake in your file has added 1 or more values that are non-numeric in that column. A lot of real data is \"messy\" like this. In these cases where there are mixed data types in a single column, Pandas usually reads the whole column as strings and assigns a data type of \"object\". This is in fact the case with our data columns winner_rank and loser_rank, which we will investigate a bit more later.\n",
    "\n",
    "### Describe() Method: Summary of Numerical Data (count, mean, std, min, quartiles, max)\n",
    "\n",
    "You can access simple statistical information for numerical data columns using the ```.describe()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282162a-7672-4b4c-a77f-e2ce2c26c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52591c2e-ac14-4e71-ade7-9832d2e4a3cc",
   "metadata": {},
   "source": [
    "Notice that ```.describe()``` returns statistical information only for numerical data columns. \n",
    "\n",
    "For which year was the earliest data record in our dataframe collected? We can see the answer is the \"min\" of the year column, 1901.\n",
    "\n",
    "To see all columns, numeric or not, you can add a parameter to ```.describe()``` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17f6af-eea5-45b4-b80d-d40783592cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4391c2-599c-48f8-96fa-077434ffe32a",
   "metadata": {},
   "source": [
    "You can now see 3 additional statistics that operate only on non-numeric data columns: unique, top, and freq. NaN appears wherever the data type is not appropriate for the statistic. \n",
    "\n",
    "Who is the most common sponsor and how many times were they a sponsor? \n",
    "\n",
    "Looking to the sponsor column, the \"top\" row indicates the most common data value is Outback Steakhouse and the \"freq\" row indicates that Outback Steakhouse was a sponsor 26 times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeacfea-d1bc-4874-b722-c83f18e7c305",
   "metadata": {},
   "source": [
    "### Info() Method: Understanding all Fields, Null Values, Dtypes, Shape, Size, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7218d-3c06-4c39-9b05-836e15302f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867edf4-b290-4d50-bde2-0883d2e0b62b",
   "metadata": {},
   "source": [
    "# III. Selecting/Slicing Data with .loc[]\n",
    "\n",
    "The Pandas function ```.loc[row, column]``` allows us to directly access rows by index and columns by name. If you have an integer in the \"row\" part, Pandas assumes this is the index of the row.\n",
    "\n",
    "## Single Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850fcaa-cd2b-4f97-8118-0e2fca0a5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a single cell - the attendance column where row index is 1\n",
    "bowlData.loc[1 , 'attendance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c9de2-801b-42c2-8451-20081587830b",
   "metadata": {},
   "source": [
    "## Single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aff753-e1c4-4988-a31b-0890067f1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT whole row of data where row index is 1\n",
    "bowlData.loc[1 , :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854480b-bf3f-4f0b-9991-82edd5944bc4",
   "metadata": {},
   "source": [
    "## Single Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028a711-8950-4184-b8cd-5d95a2822fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a single column of data, just the atttendance column\n",
    "bowlData.loc[: , 'attendance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af8e3a-43af-4708-aeeb-130e5bd14bd5",
   "metadata": {},
   "source": [
    "## Slice of Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988115e8-db87-4f7d-a357-13b30121e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a \"slice\" of rows where index is 1 to 6\n",
    "bowlData.loc[1:6 , :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479692d-9151-4c91-8860-c4deffdeda7c",
   "metadata": {},
   "source": [
    "Notice that a slice of a Pandas dataframe is inclusive of the ending index 6, such that a slice of rows 1:6 returns 6 rows. Just a quick note that this is not always the case with other Python packages. Array slicing with the Numpy or Xarray packages, for example, are exclusive of the ending index, but we'll cover that in a different notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37db1f2-0b75-4da1-ac1a-9c5a8b892e44",
   "metadata": {},
   "source": [
    "## Slice Containing All Rows, but Only Certain Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef74292-941c-4783-ab03-e6dc25ab039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT all rows but only a  \"slice\" of columns \n",
    "bowlData.loc[: , 'year':'winner_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ab211-d2f2-41da-b495-f909fceda29c",
   "metadata": {},
   "source": [
    "## Slice Containing Certain Rows, Certain Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fd3f7-515e-466b-b2f5-a73a58c52005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a \"slice\" of cells where row index is between 10 and 15 and only a few columns\n",
    "bowlData.loc[10:15 , 'year':'winner_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c215366-4f44-4621-ad2e-ac2b6a9b5ecd",
   "metadata": {},
   "source": [
    "## All Rows Where Column has Certain Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f3c5f-d570-4cee-b66d-ce030a2102a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will find all rows in the dataframe where year column is equal to 1901\n",
    "bowlData.loc[bowlData['year'] == 1901]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d359c6-f811-45cc-afd2-da6cf0125770",
   "metadata": {},
   "source": [
    "This returned only one row. If there were more rows where the year column was equal to 1901, then there would be more rows returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec8c89-fa1e-4368-8ea1-76c9d0974256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will find the locations in the dataset where sponsor is null (missing data)\n",
    "bowlData.loc[bowlData['sponsor'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef2796-b265-419a-9cbd-76e28a04c3fc",
   "metadata": {},
   "source": [
    "Notice that when your output exceeds twenty lines Jupyter will format nicely and show a bit at the ending and a bit at the end. It will do the same thing if your output has too many columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22142e50-ff2f-4bf6-9a52-dae121b51ed2",
   "metadata": {},
   "source": [
    "## Rows Based on Column Comparison\n",
    "\n",
    "If we want to return all the games where the winner was ranked below (higher number) the loser (lower number), we could do it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43d9c4-d270-4bbf-bc27-3342accee392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the winner ranked below the loser\n",
    "bowlData.loc[bowlData['winner_rank'] > bowlData['loser_rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2c26e-96be-488e-b02f-c16a9b08e154",
   "metadata": {},
   "source": [
    "Be careful in your analysis! Do you notice anything suspicious about the results that were returned?\n",
    "\n",
    "We're looking for cases where the underdog won. For example, a team that was ranked 20th, beat the team that was ranked 10th (see index 1429). If you look closely in the results above you can see multiple examples of results returned that are NOT what we asked for. For example, index 1427 shows the winner had a better rank (8th) than the loser (13th). So, we've got incorrect results but did not receive an error message. **Why did this happen??**\n",
    "\n",
    "This comes back to the data type of the columns winner_rank and loser_rank. A ranking should be a numerical data type (such as int or float). If these columns had a numeric data type then we shouldn't have experienced any problems using the greater than operator. But if those columns contain non-numeric data (dtype object, which usually indicates string data) then that could yield unexpected results when comparing if one string is greater than another. Let's take a look at the data type for winner_rank and loser_rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36f71c-b1cc-4ba7-8296-cae8cc523d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData[['winner_rank','loser_rank']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48918ba0-2f67-4db8-b440-70bb55fbf329",
   "metadata": {},
   "source": [
    "Uh oh! We can see that Pandas determined the data type of those columns to be object, which is non-numeric. We discussed briefly already why this might happen. This should indicate to us that there must be some \"messy\" data somewhere in those columns, some data values that don't look like numbers. And due to this, Pandas is treating those data columns like strings instead of numbers. So, when we ask if the winner_rank is greater than the loser_rank, the process of comparing two string values with the greater than operator returns unexpected results.\n",
    "\n",
    "When beginning work with any dataset it is best to do some data cleaning first to make sure your columns are of the expected data types and remove any whacky data values in order to avoid problems like this one. Otherwise, you might easily miss the fact that your code isn't doing what you intended.\n",
    "\n",
    "Let's see what the problem is, clean up those two columns, ensure their dtype is numeric, and try our selection again.\n",
    "\n",
    "We'll start by using a pandas function that we haven't seen yet: ```.unique()``` on the winner_rank column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f967bc2-6828-4d16-bc17-c05b6803b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all the unique data values in the winner_rank column\n",
    "bowlData['winner_rank'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bc19c-8d32-40aa-9049-167d2fff5ec6",
   "metadata": {},
   "source": [
    "Look at that! Someone has entered a value of Pennsylvania in the column of winner_rank somewhere in the data file. That doesn't make sense at all. Notice, we also have some missing data (nan), but that shouldn't cause us problems here.\n",
    "\n",
    "Let's force the winner_rank data column to be numeric using another pandas function that we haven't seen yet: ```pd.to_numeric()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32a5bad-b688-4124-a999-868c976f69c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 20., nan, 12., 13., 11., 10., 15., 16., 25., 18., 24., 22.,\n",
       "        9., 17., 21., 19., 23.,  8.,  6.,  4.,  2.,  3.,  1.,  5.,  7.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reassign all the values in the column winner_rank with numeric data values\n",
    "# any value that does not look like a number will be changed to the missing data value\n",
    "bowlData['winner_rank'] = pd.to_numeric(bowlData['winner_rank'],errors='coerce')\n",
    "\n",
    "# look again at the unique data values\n",
    "bowlData['winner_rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdc77d-34e2-4e02-9fbb-2dac67564078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the new data type\n",
    "bowlData['winner_rank'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f284048-5283-431b-9277-67a4eaea911a",
   "metadata": {},
   "source": [
    "How did we know what parameters to enter in ```pd.to_numeric()```? That information can be found in the Pandas documentation on the [API reference page for pd.to_numeric()](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html). Or you could have done a quick Google search for something like \"how to use pandas to_numeric\", which will bring up a great AI generated answer (at least it does in the USA), the link to the Pandas API reference page, and many other websites that demonstrate how to use the function.\n",
    "\n",
    "Let's check out what the problem is with loser_rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6bacc-c77f-4ac1-9dbb-df1c66717a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all the unique data values\n",
    "bowlData['loser_rank'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da2223-ee0d-4014-b2e7-5c81a18802d0",
   "metadata": {},
   "source": [
    "Again, there's a 'TN' in the data values that doesn't make any sense. We'll do the same process to clean the loser_rank column and convert to a numeric data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32cf8aa1-d73b-4292-8da9-4774b8bd7433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15., nan, 12., 25., 11., 22., 20., 14., 18.,  4., 24., 19., 17.,\n",
       "       13., 16., 23., 21.,  7.,  9., 10.,  6.,  1.,  3.,  8.,  2.,  5.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reassign all the values in the column with numeric data values\n",
    "# any value that does not look like a number will be changed to the missing data value\n",
    "bowlData['loser_rank'] = pd.to_numeric(bowlData['loser_rank'],errors='coerce')\n",
    "\n",
    "# look again at the unique data values\n",
    "bowlData['loser_rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2449c-29e1-4788-bff7-97fad1c08fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the new data type\n",
    "bowlData['loser_rank'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb32b0-8e6b-45fa-a853-8b25ec0c75ad",
   "metadata": {},
   "source": [
    "Lastly, let's try the row selection by column comparison again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a1321-f0e6-414f-b8e7-9959833d360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all rows where the winner ranked below the loser\n",
    "bowlData.loc[bowlData['winner_rank'] > bowlData['loser_rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de099b-33fd-4859-8aea-c72680ea922d",
   "metadata": {},
   "source": [
    "Notice how the result now returns 215 rows whereas before we got 255 rows. Our original selection returned 40 incorrect results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3295a-d095-4207-a6e1-a4c5b7c8d1a0",
   "metadata": {},
   "source": [
    "# IV. Selecting data with .query()\n",
    "\n",
    "Similar to ```.loc[]```, the ```.query()``` method can be used to select rows in a dataframe. Inside the ```.query()``` we can put a query that looks a little bit like a database query. You may like this method if you have experience working with databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c4c6b-98d6-4834-b7b6-20c81d0bd19a",
   "metadata": {},
   "source": [
    "## Rows Where Column has Certain Numerical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af4575-2e34-40b9-a98d-6ed394c4a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where year is equal to 1901 using .query\n",
    "bowlData.query(\"year == 1901\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd8256-fb6c-48bd-96b9-9459b79fb3de",
   "metadata": {},
   "source": [
    "## Rows Where Column has String Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fc563-60b9-4476-80bb-6d03c94b3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the bowl_name is \"Rose Bowl\"\n",
    "# notice the single quotes around the string \"Rose Bowl\"\n",
    "bowlData.query(\"bowl_name == 'Rose Bowl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c979285-cbe7-4d64-b918-42545f2abc4e",
   "metadata": {},
   "source": [
    "## Rows Based on Substring Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf2a60-8037-4c44-ade3-84f2a3ca3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all rows where the word \"State\" appears in the winner_tie column\n",
    "bowlData.query(\"winner_tie.str.contains('State')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efcf6df-0570-4f1e-a21a-ce544a6bcd0e",
   "metadata": {},
   "source": [
    "## Rows Based on Column Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d2ddb-2292-4e57-a01a-414739a274b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the loser ranked higher (smaller number) than the winner (larger number) using .query\n",
    "bowlData.query(\"loser_rank < winner_rank\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340d906f-6310-4bd8-8a88-d5c58cd609ab",
   "metadata": {},
   "source": [
    "## Rows Based on Comparison with a Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757dbd8-1f41-4052-97e4-a9eda277d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get the mean winner_points x 2\n",
    "# .mean() is calculating the mean of the entire winner_points column\n",
    "twiceTheMean = bowlData.winner_points.mean() * 2\n",
    "\n",
    "# then, we can use that value to query for winners with more than twice the mean\n",
    "bowlData.query(\"winner_points > @twiceTheMean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8602a21-a87c-45b7-adc3-eec65294854a",
   "metadata": {},
   "source": [
    "## Multiple Criteria Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba255f5-9e21-4f4e-9d34-68820a538031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the rows where the winner is Alabama, \n",
    "# AND Alabama had more than 50 points, \n",
    "# AND they weren't ranked number 1.\n",
    "bowlData.query(\"(winner_tie == 'Alabama') and (winner_points > 50) and (winner_rank > 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d708ce95-f025-4673-8fb2-d7a4f201ec3e",
   "metadata": {},
   "source": [
    "# V. Querying a Dataframe without .query()\n",
    "\n",
    "Different syntax can be used to accomplish the same data queries we covered above without using ```.query()```. This syntax may be preferable if you don't have experience working with databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0f6c6-bbf3-497f-94dc-966632b80065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where year is equal to 1901 using .query\n",
    "\n",
    "# copy of code from the .query() section\n",
    "# bowlData.query(\"year == 1901\") \n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[bowlData.year==1901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d57ef67-8e0d-4f14-8d92-0e711633438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the bowl_name is \"Rose Bowl\"\n",
    "\n",
    "# copy of code from the .query section\n",
    "# bowlData.query(\"bowl_name == 'Rose Bowl'\") \n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[bowlData.bowl_name==\"Rose Bowl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb937af4-5de8-4e11-89e3-e03b11b2de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all rows where the word \"State\" appears in the winner_tie column\n",
    "\n",
    "# copy of code from the .query section\n",
    "# bowlData.query(\"winner_tie.str.contains('State')\")\n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[bowlData.winner_tie.str.contains('State')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c03f8-ccf9-469d-9964-6fbda5f22191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where the loser ranked higher (smaller number) than the winner (larger number) using .query\n",
    "# copy of code from the .query section\n",
    "# bowlData.query(\"loser_rank < winner_rank\")\n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[bowlData.loser_rank < bowlData.winner_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cd6e8-b785-48aa-b1db-7ac8919f1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows Based on Comparison with a Variable\n",
    "\n",
    "# copy of code from the .query section\n",
    "# First, let's get the mean winner_points x 2\n",
    "# twiceTheMean = bowlData.winner_points.mean() * 2\n",
    "# then, we can use that value to query for winners with more than twice the mean\n",
    "# bowlData.query(\"winner_points > @twiceTheMean\")\n",
    "\n",
    "# alternative query syntax\n",
    "twiceTheMean = bowlData.winner_points.mean() * 2  # the same\n",
    "bowlData[bowlData.winner_points > twiceTheMean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f4a2b-e40a-4479-a0e3-eae6f38a6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the rows where the winner is Alabama, \n",
    "# AND Alabama had more than 50 points, \n",
    "# AND they weren't ranked number 1.\n",
    "\n",
    "# copy of code from the .query section\n",
    "# bowlData.query(\"(winner_tie == 'Alabama') and (winner_points > 50) and (winner_rank > 1)\")\n",
    "\n",
    "# alternative query syntax\n",
    "bowlData[(bowlData.winner_tie == 'Alabama') & (bowlData.winner_points > 50) & (bowlData.winner_rank > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97e202-2970-4079-bb85-4da7688a281e",
   "metadata": {},
   "source": [
    "Notice the difference here where we're using '&' to link multiple conditions together instead of how in the previous notebook Python Language Basics we learned how to use the boolean operator 'and' to link multiple conditions. The '&' is called  'bitwise and' whereas python 'and' is called a 'logical and'. Unless using ```.query()```, Pandas requires bitwise and, bitwise or, and bitwise not, which are written as: &, |, ~. Otherwise, you will get an error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2334e5d-aabd-4983-af0f-27c1eab5bfcc",
   "metadata": {},
   "source": [
    "# VI. DataFrame Manipulation\n",
    "\n",
    "## Summary Functions\n",
    "\n",
    "Pandas offers a handful of summary functions that can be applied to a column or columns of a dataframe (series objects). These functions are:\n",
    "\n",
    "- ```.sum()``` Sum values of each object. \n",
    "- ```.count()``` Count non-NA values of each object. \n",
    "- ```.median()``` Median value of each object. \n",
    "- ```.quantile([0.25,0.75])``` Quantiles of each object. \n",
    "- ```.apply(function)``` Apply function to each object. \n",
    "- ```.min()``` Minimum value in each object. \n",
    "- ```.max()``` Maximum value in each object. \n",
    "- ```.mean()``` Mean value of each object. \n",
    "- ```.var()``` Variance of each object. \n",
    "- ```.std()``` Standard deviation of each object.\n",
    "\n",
    "We won't cover all of these, but let's try a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac01c4b4-f448-4ad7-89b2-232ff5cbeb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winners had an average of  30.25343811394892\n",
      "Losers had a median of  30.0\n",
      "The highest score of a losing team is 61\n"
     ]
    }
   ],
   "source": [
    "# the mean of winner_points\n",
    "print(\"Winners had an average of \",bowlData['winner_points'].mean())\n",
    "\n",
    "# the median of loser_points\n",
    "print(\"Losers had a median of \",bowlData['winner_points'].median())\n",
    "\n",
    "# lowest score of a winning team\n",
    "print(f\"The highest score of a losing team is {bowlData['loser_points'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c599e41-166f-40e2-b493-64324491fff8",
   "metadata": {},
   "source": [
    "Wow, 61 points and still a loss... ooof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6332d081-de63-4ea5-a9b9-1468253a0ef3",
   "metadata": {},
   "source": [
    "## Sorting Data\n",
    "\n",
    "Let's begin with a simple sort. To sort properly, we need the data column we are using for the sort to be numeric, otherwise we will get unexpected results (probably without warning or error) as we saw earlier in the notebook when we were comparing the values of winner_rank to loser_rank. \n",
    "\n",
    "What if we want to sort the dataframe by year but only return a few columns of data?\n",
    "\n",
    "Let's first double check that the year column of the dataframe is numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e8575-6eb9-4318-becd-9897b120fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.year.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a47dd-ad91-4feb-971a-ef0d0f6781f0",
   "metadata": {},
   "source": [
    "Excellent, we should be good to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f399cb-2983-4cb4-950a-920b48e82bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort specific columns by year\n",
    "bowlData[['year','winner_rank','loser_rank','winner_points']].sort_values(by=['year'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26dfb52-76cd-4dca-a8a8-09aaf634f2fd",
   "metadata": {},
   "source": [
    "Now, let's do a more complex sort. Sort by winner_points to find the highest score by an upset winner (winner ranked lower than loser).\n",
    "\n",
    "We'll use the columns winner_rank and loser_rank to accomplish this sort (which we have already converted to numeric data) as well as the winner_points column.\n",
    "\n",
    "Let's double check the data type of the winner_points column before we sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb5a56-d00d-49c2-81e6-a290f8bc8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.winner_points.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99372a0a-6118-48c6-9ca0-de6fbfc565d0",
   "metadata": {},
   "source": [
    "Great, another numeric data column. This column is ok to sort on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da5fb79-0eae-4210-8d9d-472b818ce8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by winner_points to find the highest score by an upset winner\n",
    "bowlData[bowlData.winner_rank > bowlData.loser_rank].sort_values(by=['winner_points'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b6885-130d-4c59-b9e5-ea55d29a8ba0",
   "metadata": {},
   "source": [
    "Notice that our code returned a lot of rows but we'll find the answer to our question in the first row in the winner_points column: 70.\n",
    "\n",
    "How would we do the same sort but return only the highest score by an upset winner as opposed to all the data rows that were returned in the code above?\n",
    "\n",
    "Since we are sorting with ascending = False, the highest winner_points is located in the first row of returned data. In this case, the index of the first row is 727. We don't know ahead of time what the index value of the first row of results with be though. Don't worry! We can grab the first row of the sorted results using the integer row position (0) as opposed to using the row index by using ```.iloc[]```.\n",
    "\n",
    "From the results above we expect the output of the following code to be 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9541969-88da-4b40-a337-e5b18cf89eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by the winner_points to find the highest score by an upset winner\n",
    "bowlData[bowlData.winner_rank > bowlData.loser_rank].sort_values(by=['winner_points'], ascending=False).iloc[0].loc['winner_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69713c85-1897-469f-86b4-00f62f48f0aa",
   "metadata": {},
   "source": [
    "Wow! What just happened? We used ```.iloc[0]``` to select only the first row of the results returned by sorting and ```.loc['winner_points']``` to return the value of the winner_points column from the results return by ```.iloc[0]```. \n",
    "\n",
    "Are you beginning to see the power of Pandas? We can string together many functions in a row to achieve what we're looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9b602-10e7-4ee4-bad4-b294c1350378",
   "metadata": {},
   "source": [
    "## Grouping Data\n",
    "\n",
    "```.groupby()``` will partition data into groups for you, which you can then operate on using functions like```.mean()```, ```.sum()```, etc. Let's start with a super simple example before we try to use ```.groupby()``` on our bowlData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0d05b-a2be-487f-8eb6-4a767bb98cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new very simple dataframe \n",
    "# pretend we have been observing two falcons and two parrots\n",
    "# and we are keeping data records on their maximum observed flight speed in miles per hour\n",
    "df = pd.DataFrame({'species': ['falcon', 'falcon','parrot', 'parrot'],\n",
    "                   'individual': ['f01','f02','squawky','pretty boy'],\n",
    "                   'max_speed_mph': [230., 240., 35., 40.]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6c5fa-23a0-489a-a8da-17a2948d7497",
   "metadata": {},
   "source": [
    "We can use ```.groupby``` to find the average max speed of each species if we group the dataframe rows by the species column and then for each group of rows (there will be two groups: falcon rows and parrot rows) take the mean of the max_speed_mph column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb0a36-7b30-4ff4-86a2-27eef38e55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"species\")['max_speed_mph'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59a289e-79f8-4cb9-8212-a78a75561cc5",
   "metadata": {},
   "source": [
    "Nice! The average max speed of all the falcons is 235 mph and the average max speed of all the parrots is 37.5 mph.\n",
    "\n",
    "Pandas ```.groupby()``` will work similarly on our much larger bowlData dataframe.\n",
    "\n",
    "Let's group by winner_tie (which is the name of the winning team) and then find the average numer of points the winning team scored (winner_points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ba502-1ea0-4652-aac4-64335a113e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgPointsByWinners = bowlData.groupby(\"winner_tie\")[\"winner_points\"].mean()\n",
    "avgPointsByWinners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd1fb3-afe7-420a-9ead-a811239f5ec8",
   "metadata": {},
   "source": [
    "With the bowlData, it is a little more obvious to see the default behaviour of the ```.groupby()``` with regard to sorting the result. ```.groupby()``` will sort ascending on the grouping column (here, winner_tie) when returning the result, which is why our result is sorted by winner_tie from A to Z. This is the default behavior unless you specify sort=False as a parameter in ```.groupby```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb63aa1-27b7-4988-8508-7f29edaadd1a",
   "metadata": {},
   "source": [
    "## Renaming Columns\n",
    "\n",
    "To change column names, the easiest way is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bad0f-b3c3-45c6-a32e-cdebed5e3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary where key is the old name and value is the new name\n",
    "columnMap = {\"mvp\":\"most_valuable_player\", \"winner_tie\":\"winner\"}\n",
    "\n",
    "bowlData = bowlData.rename(columns=columnMap, errors=\"raise\")\n",
    "\n",
    "bowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c2032-484e-4204-b6ec-5a65aae5ed2c",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Sometimes you will need to assess how much of your data is missing to make sure any statistics you apply to your data are robust. \n",
    "\n",
    "Sometimes having the missing data value (NaN) in your data is beneficial. Many functions will simply ignore missing data or propagate missing data values. For example, if you were to add one data value to another and the values were NaN + 5, the result would be NaN. This is often desirable.\n",
    "\n",
    "But in some cases, like for various machine learning techniques, you may need to ensure that there are no missing data values present in your data at all. In this case you may need to fill the missing data values with a different number or drop rows with missing data from your dataframe entirely.\n",
    "\n",
    "Let's look at the Pandas functions that can help us with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb03885-cdb3-4dba-b598-e0ecb2b33b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how many missing values are present in each column\n",
    "bowlData.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947c588-ac9b-4b2c-9240-6e29f2e49426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all the rows where winner_rank is missing\n",
    "bowlData[bowlData['winner_rank'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ebac7-3f77-4420-96e5-e0d0101008e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all missing values with 0 \n",
    "# notice we are making a copy of our data by saving the dataframe to a new variable here\n",
    "betterBowlData = bowlData.fillna(0)\n",
    "\n",
    "# let's see if any missing values are still present - shouldn't be\n",
    "betterBowlData.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42932d0d-38c9-4583-99f3-363bba074627",
   "metadata": {},
   "source": [
    "Let's pause for a minute to think about what we just did. We filled all NaN with 0. Does that make sense? Does it make sense to have winner_points = 0 or sponsor = 0? You can see how filling NaN with another value may end up being confusing to you later. So think carefully if you really need to replace missing data values, or if filling with another value like 0 will work for your analysis. \n",
    "\n",
    "Instead of filling NaN with a different value, you may need to drop full data rows if there are any missing values present. This is how you would do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd2988-4ef2-459e-8ffc-dbb9ab0cac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows where at least 1 column of data is NaN\n",
    "lessBowlData=bowlData.dropna(how='any')\n",
    "lessBowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745f455a-c01b-47ac-8cbc-d28812bbdffb",
   "metadata": {},
   "source": [
    "When we first loaded bowlData, we originally had 1527 rows of data and now after dropping all rows that have at least one missing value, we are left with only 269 rows of data.\n",
    "\n",
    "If the goal was to drop all rows where all columns contain the missing data value, you could use ```.dropna(how='all')```.\n",
    "\n",
    "## Creating New Columns Derived from Existing Columns\n",
    "\n",
    "Pandas allows us to easily use existing columns to calculate new data and save the calculations into a new column in the dataframe. \n",
    "\n",
    "Here's an example. Let's define a 'blowout' as when the winning team beats the losing team by 21 or more points. The task now is to create a new column in our dataframe that indicates whether each game (row) in our dataset was a blowout. We'll fill the column with values of True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d6205-8424-42b2-8d6b-fea0f5103de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData['blowout'] = bowlData.winner_points - bowlData.loser_points >=21\n",
    "bowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5876724-ad9f-42f2-a493-3e33439e4350",
   "metadata": {},
   "source": [
    "It's that simple! There is no looping required. Pandas is smart enough to do the subtraction row by row and fill the result in the appropriate place all on its own. Writing a loop would be much slower, which is the case for many Python packages. It's most efficient to use the built-in capabilities of whatever packages you're working with. Try to avoid looping wherever you can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e323abf0-65e7-44ba-bfa7-d14c4d4f036d",
   "metadata": {},
   "source": [
    "## Merging DataFrames Together\n",
    "\n",
    "Let's pretend I have additonal college football bowl data hanging out in a separate csv file. The additional data has the same 'id' information as in collegefootballbowl.csv, but not all id's (1-1527) are present. How do I join this additional data to the bowlData dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08e669-2a41-4f47-9055-f98ac72639c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "moreBowlData = pd.read_csv('data/morecollegefootballbowldata.csv')\n",
    "moreBowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730cdcf-3a40-4d8f-8d4c-fb22ba795bba",
   "metadata": {},
   "source": [
    "Oh wow, that's not much data! But let's merge it into bowlData anyway. The merge column will be the id column since that is the only common column between the two data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032d63e-1d08-4621-9335-6dfcb91287a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allBowlData = pd.merge(bowlData,moreBowlData,how='outer',on='id')\n",
    "allBowlData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2c00c-a4ee-40c9-9a98-82f9481e70b9",
   "metadata": {},
   "source": [
    "We can see that for the 3 id's where we have tickets_sold and best_selling_concession data, those data values now appear in the merged dataframe. And everywhere else in those two columns got filled with NaN. There are tons of ways to merge dataframes. Check out the [pd.merge() API reference](https://pandas.pydata.org/docs/reference/api/pandas.merge.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd53be-6504-4c0b-89a0-30a5c451720d",
   "metadata": {},
   "source": [
    "# VII. Writing a DataFrame to a File\n",
    "\n",
    "Pandas has a function ```.to_csv()``` for writing a dataframe to a .csv file.\n",
    "\n",
    "Let's write our bowl data to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87da19-5c4e-4250-8368-bfa26d56c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlData.to_csv(r'data/bowlData.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42da04-d7bc-454d-ba9b-818c51fb02af",
   "metadata": {},
   "source": [
    "Locate the file you just wrote, open it, and see what it looks like. If you open the file in JupyterLab it will look like a spreadsheet. If you open the file with any other text editor, you should see the comma separated header and data values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27809429-0ce6-4744-9a9a-3892ca3f18c6",
   "metadata": {},
   "source": [
    "# VIII. Learning More About Pandas\n",
    "\n",
    "For more about Pandas, start on the Pandas website where you can find:\n",
    "\n",
    "- a nice cheat sheet https://pandas.pydata.org/docs/getting_started/index.html\n",
    "- a long list of community developed tutorials https://pandas.pydata.org/docs/getting_started/tutorials.html#communitytutorials\n",
    "- the user guide, which contains a bunch of 10 minute learning guides as well as more in-depth guides by topic https://pandas.pydata.org/docs/user_guide/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc2619-716d-47e8-b9a7-c6158797d07a",
   "metadata": {},
   "source": [
    "# IX. Pandas Exercise Using Weather Data\n",
    "\n",
    "Use Pandas to read, clean, manipulate, and aggregate weather data.\n",
    "\n",
    "## Read the data file\n",
    "Read the file at data/weatherdata.csv into a Pandas dataframe and render the dataframe to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c0cf4c4-8402-49e6-8a4c-b33795d116b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3467a56c-5a71-4302-b028-a63feff66b20",
   "metadata": {},
   "source": [
    "Show the data type of each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2b6cf83-d0c1-4ca6-87a5-eb2bb61263ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded0cb9-e9ba-4484-ac96-43309f5ceb81",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "Look at all the columns of data. Do you see any mistakes?\n",
    "\n",
    "Replace 'LosAngeles' at index 3 with 'Los Angeles'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32612b2d-e39c-4317-b6bb-b47fcd404615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c246d-fe5f-4f41-a867-8fa14914f065",
   "metadata": {},
   "source": [
    "What data type is the windspeed_knots column? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950ddcb-3e7c-4784-b1c8-47aa174b2333",
   "metadata": {},
   "source": [
    "Type your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf2ecb-2a56-46ac-b6d3-7317567638bc",
   "metadata": {},
   "source": [
    "Why did Pandas assign that data type to windspeed_knots?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f087b-1658-4338-9432-b9671e5f3e9d",
   "metadata": {},
   "source": [
    "Type your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b532849-75da-4dfb-98bb-a4d1914d944c",
   "metadata": {},
   "source": [
    "Judging by the data values in the windspeed_knots column, what data type should windspeed_knots probably be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfa38e-feda-45c3-8a3e-534b74eee0eb",
   "metadata": {},
   "source": [
    "Type your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbdc2f-4b03-4140-b8bb-47458a1348fb",
   "metadata": {},
   "source": [
    "Force the windspeed_knots column to be numeric, then show that the data type of the column did in fact change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce8e0abe-8c28-435d-ba07-471ad287d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2af43-be8e-4d3c-835c-23235524ffdc",
   "metadata": {},
   "source": [
    "## Create a new column of data\n",
    "\n",
    "Create a column of boolean data called ```IsRainy``` that indicates whether there was precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d119e9b-2426-4adc-9bb8-f7a650caee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2dcbf4-fdc9-476e-9d5d-da1ef28825b9",
   "metadata": {},
   "source": [
    "## Calculate average temperature by city\n",
    "\n",
    "Calculate the average temperature for each city and save the result as new variable called ```avgT```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19110cad-e27d-4e69-bf94-705aef3fd0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9765d01-9bcc-42f3-9c10-aafe3efc3e50",
   "metadata": {},
   "source": [
    "Looking at the ```df``` dataframe and the ```avgT``` results, how many data values were used to calculate the average New York temperature? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222a471-f968-495d-a543-445fd1c108bb",
   "metadata": {},
   "source": [
    "Type your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8de70-ca94-4f4e-a02c-d695bc24a655",
   "metadata": {},
   "source": [
    "## Sort the dataframe by date, ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da2170d7-c6a5-4a09-a46e-044fc0f4c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e48227f-4314-4f86-a922-4b285eb50c61",
   "metadata": {},
   "source": [
    "## Write the dataframe to file\n",
    "\n",
    "Write the ```df``` data to a file called ```weatherdata_yourname.csv```, replacing yourname with your first name. Do not include the index column, but do include the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b8e697e-4ae4-46bf-90c2-2ea2abb5fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc69db-015b-4e89-9d58-b099676a4ecf",
   "metadata": {},
   "source": [
    "Does your csv file look like this inside?\n",
    "\n",
    "<img src=\"images/weatherdata.png\" alt=\"contents of cvs file\" width=\"400\"/>\n",
    "\n",
    "If so, congratulations! You've successfully completed this exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnbydoing",
   "language": "python",
   "name": "learnbydoing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
